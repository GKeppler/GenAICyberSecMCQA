# LLM Cybersecurity Question Answering

## Installation / Start
1. Run the command: `sbatch jer-ssh-code-server.sh`
2. Check the queue with: `squeue`
3. Connect to the server with: `ssh sb7059@haicore.scc.kit.edu -L 8077:{NODE-ID}:8077`
4. Connect using VS Code.

## MCQ LLM MMLU CISCO
The config file stores the settings for the Jupyter Notebook `mcqa_LLM_mmlu_cisco`.

## Settings
- **control_output**: Prints all configuration options before the main loop.
- **workspace_dir**: Path to the main directory of stored LLMs.
- **model_paths**: Dictionary of model names and paths. For each uncommented/added model, the loop will run.
- **model_parameters**:
  - **temperature**: 0
  - **max_output_token**: For MMLU, set to 1 since only single choice.
- **max_sampling_rate**: Defines how often the same questions will be asked.
- **num_of_shuffles**: Defines how often the choices of a given question will be shuffled. 1 means no shuffling.
- **number_of_questions**: Sets the maximum number of asked questions. If fewer questions are available, it will take as many as there are.

## Run the Script
1. Import necessary libraries.
2. Define the path of the config file (currently MMLU & Cisco 201-301).
3. Define functions for evaluation and plotting.
4. Load and store configurations in variables.
5. Control output of all configurations.
6. Main loop: iterate over all questions and models.
7. Plot the evaluation of the results.

## Folder Description
1. **Archive**: Old files.
2. **data**: Datasets in xlsx format, parquet.
3. **results**: Storage of capability test results. Folder names are defined inside the configuration file.

## Description of GIT
The main file is **mcqa_LLM_mmlu_cisco.ipynb**. To run the script:
1. Load/configure a config file.
2. Change the path of the config file inside the main script.
3. Run the script.

With the configuration file, you can decide to run the MMLU test or the CISCO test. The results of the test are stored inside the results folder with the corresponding name of the test and the current date. There is also a .png file of the results stored. The metadata of the run is stored inside the JSON file.

Inside the configuration file, you can decide whether to store the results of a run with the parameter **track_results**. You can also choose to print the results during a run with the parameter **print_results**.
