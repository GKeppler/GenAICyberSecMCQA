{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain_community.llms import LlamaCpp\n",
    "from langchain.callbacks.manager import CallbackManager\n",
    "import pandas as pd\n",
    "from langchain import hub\n",
    "from langchain_chroma import Chroma\n",
    "from langchain import PromptTemplate\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain.embeddings import LlamaCppEmbeddings\n",
    "from langchain_community.embeddings.sentence_transformer import (SentenceTransformerEmbeddings)\n",
    "import re\n",
    "from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT = \"\"\"You are an assistant tasked with summarizing tables and text. \n",
    "Give a concise summary of the given table and text.\n",
    "{content_of_pdf} \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOOK_PDF = '/home/iai/sb7059/git/llm_test/data/Book/industrial-cybersecurity-efficiently-monitor-the-cybersecurity-posture-of-your-ics-environment_compress.pdf'\n",
    "PATH = '/home/iai/sb7059/git/llm_test/data/Book/Images'\n",
    "#BOOK_PDF = '/home/iai/sb7059/git/llm_test/data/Book/fdgth-06-1321485.pdf'\n",
    "#BOOK_PDF = '/home/iai/sb7059/git/llm_test/data/Book/smeggitt.pdf'\n",
    "WORKSPACE_DIC = \"/hkfs/work/workspace_haic/scratch/sb7059-llm_models_jeremy\"\n",
    "\n",
    "MODEL_PATH = { #\"Mixtral-8x-7b\": WORKSPACE_DIC + \"/Mixtral/mixtral-8x7b-instruct-v0.1.Q4_K_M.gguf\",\n",
    "               #\"Phi-2\": WORKSPACE_DIC + \"/Phi/Phi2/phi-2.Q4_K_M.gguf\",\n",
    "               \"Llama2-70b\": WORKSPACE_DIC + \"/Llama/Llama2/llama-2-70b.Q5_K_M.gguf\",\n",
    "                \"Phi-3-medium-128k\": WORKSPACE_DIC + \"/Phi/Phi3/Phi-3-mini-4k-instruct-q4.gguf\",\n",
    "               #\"LLama-3-70b\": WORKSPACE_DIC + \"/Llama/LLama3/Meta-Llama-3-70B-Instruct-v2.Q4_K_M.gguf\",\n",
    "               #\"Mixtral-8x22b\": WORKSPACE_DIC + \"/Mixtral/Mixtral-8x22b-Instruct\",\n",
    "               #\"Mixtral-8x-22b\": WORKSPACE_DIC + \"/Mixtral/Mixtral-8x22B-Instruct-v0.1.Q4_K_M-00001-of-00002.gguf\",\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_tables_to_string(page):\n",
    "    \"\"\"\n",
    "    Extracts all tables from a given page and concatenates them into a single string.\n",
    "\n",
    "    Parameters:\n",
    "    - page: The page object from which to extract tables.\n",
    "\n",
    "    Returns:\n",
    "    - A string containing all tables extracted from the page.\n",
    "    \"\"\"\n",
    "    content_of_pdf = \"\"\n",
    "    tabs = page.find_tables()  # detect the tables\n",
    "    for i, tab in enumerate(tabs):  # iterate over all tables\n",
    "        df = tab.to_pandas()\n",
    "        # Add the table to a string to be used in the prompt\n",
    "        content_of_pdf += df.to_string()\n",
    "    return content_of_pdf\n",
    "\n",
    "def extract_and_save_images(page, doc, PATH):\n",
    "    \"\"\"\n",
    "    Extracts all images from a given page and saves them to a specified path.\n",
    "\n",
    "    Parameters:\n",
    "    - page: The page object from which to extract images.\n",
    "    - doc: The document object containing the page.\n",
    "    - PATH: The file path where images will be saved.\n",
    "    \"\"\"\n",
    "    for i in page.get_images(full=True):\n",
    "        xref = i[0]\n",
    "        image = fitz.Pixmap(doc, xref)\n",
    "        with open(f'{PATH}/image_{xref}.png', 'wb') as f:\n",
    "            f.write(image.tobytes())\n",
    "\n",
    "def extract_spans_from_blocks(block_dict):\n",
    "    # Initialize an empty list to store row data\n",
    "    rows = []\n",
    "    \n",
    "    # Iterate through each page and its blocks\n",
    "    for page_num, blocks in block_dict.items():\n",
    "        for block in blocks:\n",
    "            # Check if the block is of type 0 (text)\n",
    "            if block['type'] == 0:\n",
    "                for line in block['lines']:\n",
    "                    for span in line['spans']:\n",
    "                        # Extract bounding box and other span properties\n",
    "                        xmin, ymin, xmax, ymax = list(span['bbox'])\n",
    "                        font_size = span['size']\n",
    "                        text = unidecode(span['text'])\n",
    "                        span_font = span['font']\n",
    "                        is_bold = \"bold\" in span_font.lower()\n",
    "                        \n",
    "                        # Ensure the text is not just whitespace\n",
    "                        if text.replace(\" \", \"\"):\n",
    "                            rows.append((xmin, ymin, xmax, ymax, text, is_bold, span_font, font_size, page_num))\n",
    "    \n",
    "    # Create a DataFrame from the rows\n",
    "    span_df = pd.DataFrame(rows, columns=['xmin', 'ymin', 'xmax', 'ymax', 'text', 'is_bold', 'span_font', 'font_size', 'page_num'])\n",
    "    return span_df\n",
    "\n",
    "def get_title(span_df):\n",
    "    title_page = span_df[span_df['page_num'] == 1]\n",
    "    unique_font_sizes_title = title_page['font_size'].unique()\n",
    "    title = \"\"\n",
    "    for index, row in title_page.iterrows():\n",
    "        #Check if the row is bold and if the font size is the greatest font size\n",
    "        if row['font_size'] == max(unique_font_sizes_title): \n",
    "            title += row['text']\n",
    "    return title\n",
    "\n",
    "def extract_toc_as_df(pdf_path):\n",
    "    # Open the PDF\n",
    "    doc = fitz.open(pdf_path)\n",
    "    \n",
    "    # Extract the table of contents\n",
    "    toc = doc.get_toc()\n",
    "    \n",
    "    # Close the document\n",
    "    doc.close()\n",
    "    \n",
    "    # Convert TOC to DataFrame\n",
    "    toc_df = pd.DataFrame(toc, columns=['Level', 'Title', 'Page'])\n",
    "    \n",
    "    return toc_df\n",
    "\n",
    "def extract_pdf_content(pdf_path, start_page, end_page):\n",
    "    pdf_document = fitz.open(pdf_path)\n",
    "    pdf_content = []\n",
    "    block_dict = {}\n",
    "    for page_number in range(start_page, end_page):\n",
    "        page = pdf_document[page_number]\n",
    "        file_dict = page.get_text('dict') # Get the page dictionary\n",
    "        block = file_dict['blocks'] # Get the block information\n",
    "        block_dict[page_number] = block\n",
    "\n",
    "        page_content = page.get_text()\n",
    "        pdf_content.append(page_content)\n",
    "\n",
    "        # Extract images from the page\n",
    "        extract_and_save_images(page, pdf_document, PATH)\n",
    "\n",
    "        # Extract tables from the page\n",
    "        pdf_content.append(extract_tables_to_string(page))\n",
    "\n",
    "    display(analyse_content(extract_spans_from_blocks(block_dict),page))\n",
    "    \n",
    "    return pdf_content\n",
    "\n",
    "\n",
    "def analyse_content(span_df, page):\n",
    "    # Initialize lists to hold categorized content\n",
    "    site_header = []\n",
    "    headers = []\n",
    "    subheader = []\n",
    "    subsubheader = []\n",
    "    important_texts = []\n",
    "    picture_descriptions = []\n",
    "    page_content = []\n",
    "\n",
    "    # Calculate font size and font type statistics\n",
    "    font_size_counts = span_df['font_size'].value_counts()\n",
    "    font_count = span_df['span_font'].value_counts()\n",
    "    unique_font_sizes = sorted(span_df['font_size'].unique(), reverse=True)\n",
    "\n",
    "    # Define thresholds\n",
    "    header_threshold = page.rect.height * 0.07\n",
    "\n",
    "    # Iterate through each row in the DataFrame\n",
    "    for index, row in span_df.iterrows():\n",
    "        text = row['text']\n",
    "        font_size = row['font_size']\n",
    "        is_bold = row['is_bold']\n",
    "        ymin = row['ymin']\n",
    "        \n",
    "        # Site Header - typically at the top of the page\n",
    "        if ymin < header_threshold:\n",
    "            site_header.append(text)\n",
    "\n",
    "        # Determine if text is a header or subheader based on font size and boldness\n",
    "        if is_bold \n",
    "            \n",
    "        \n",
    "        and font_size == unique_font_sizes[0]:\n",
    "            headers.append(text)\n",
    "        elif is_bold and font_size == unique_font_sizes[1]:\n",
    "            subheader.append(text)\n",
    "        elif is_bold and font_size != font_size_counts.idxmax():\n",
    "            subsubheader.append(text)\n",
    "\n",
    "        # Bold text that is not categorized as headers or subheaders\n",
    "        if is_bold and font_size == font_size_counts.idxmax():\n",
    "            important_texts.append(text)\n",
    "\n",
    "        # Check for figure descriptions\n",
    "        if \"figure\" in text.lower() or \"fig.\" in text.lower() or \"image\" in text.lower():\n",
    "            picture_descriptions.append(text)\n",
    "\n",
    "        # Default page content\n",
    "        page_content.append(text)\n",
    "\n",
    "    # Store results in a dictionary\n",
    "    data = {\n",
    "        \"site_title\": site_header,\n",
    "        \"headers\": headers,\n",
    "        \"subheader\": subheader,\n",
    "        \"subsubheader\": subsubheader,\n",
    "        \"important_texts\": important_texts,\n",
    "        \"picture_descriptions\": picture_descriptions,\n",
    "        \"page_content\": page_content\n",
    "    }\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'site_title': ['What is an ICS?     23'],\n",
       " 'headers': ['The opportunities', 'The risk'],\n",
       " 'subheader': ['Internet Protocol',\n",
       "  'IP',\n",
       "  'Transport Control Protocol',\n",
       "  'TCP',\n",
       "  'User Datagram Protocol',\n",
       "  'UDP'],\n",
       " 'subsubheader': [],\n",
       " 'important_texts': ['Internet Protocol',\n",
       "  'IP',\n",
       "  'Transport Control Protocol',\n",
       "  'TCP',\n",
       "  'User Datagram Protocol',\n",
       "  'UDP'],\n",
       " 'picture_descriptions': [],\n",
       " 'page_content': ['What is an ICS?     23',\n",
       "  'Knowing that some of the processes an OT/ICS system controls are expected to run ',\n",
       "  'flawlessly and uninterrupted for weeks--or even months--at a time, it is easy to see ',\n",
       "  'why here, the availability requirement is king. Integrity is a close second, as we want ',\n",
       "  'to make sure that data that the OT systems and operators are making decisions on is ',\n",
       "  'free from error or manipulation. Confidentiality is hardly a major concern in a typical ',\n",
       "  'OT environment, other than maybe with some historical data stored in a database or ',\n",
       "  'in log files on a server or PC. This is because by the time the data is used, it is pretty ',\n",
       "  'much worthless already; though as I said, stored production data, recipes, and--in some ',\n",
       "  'cases--the control applications that are stored on storage media do have some value, and ',\n",
       "  'therefore the ',\n",
       "  'C ',\n",
       "  'in the CIA triad should not be completely ignored.',\n",
       "  'The opportunities',\n",
       "  \"Why did IT and OT convergence occur? Wouldn't it make much more sense to keep the \",\n",
       "  'two separated? Yes--from a security perspective, it would definitely make sense to keep ',\n",
       "  'things as separate as possible. However, from a business perspective, having accurate, ',\n",
       "  'on-the-fly, and relevant data coming from the OT environment makes a lot of sense. Such ',\n",
       "  'information allows tighter production scheduling, can decrease the amount of inventory ',\n",
       "  'that needs to be held on site, helps cost calculation, and provides many more logistical ',\n",
       "  'advantages. Modern ERP and MES systems rely on input and information from both the ',\n",
       "  'production and the enterprise side of a business. Those reasons--and many more--have ',\n",
       "  'driven the convergence of IT and OT systems. ',\n",
       "  'The risk',\n",
       "  'As stated earlier in this chapter, the ICS (the OT environment) was originally built with, ',\n",
       "  'and around, proprietary devices, equipment, and networking media and protocols, ',\n",
       "  'without security in mind. Just about every vendor had their own way of doing things, and ',\n",
       "  'every one of them had a different way of configuring, operating, and maintaining their ',\n",
       "  'setup. This proprietary behavior did not work well with the whole IT/OT convergence ',\n",
       "  'demand, and slowly ICS equipment vendors started adhering to a common set of ',\n",
       "  'standards--namely, the widely used networking protocols Ethernet, ',\n",
       "  'Internet Protocol',\n",
       "  '(',\n",
       "  'IP',\n",
       "  '), ',\n",
       "  'Transport Control Protocol',\n",
       "  ' (',\n",
       "  'TCP',\n",
       "  '), and the ',\n",
       "  'User Datagram Protocol',\n",
       "  ' (',\n",
       "  'UDP',\n",
       "  ')--to ',\n",
       "  'run their controls and automation protocols over. ']}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"What is an ICS?     23\\nKnowing that some of the processes an OT/ICS system controls are expected to run \\nflawlessly and uninterrupted for weeks—or even months—at a time, it is easy to see \\nwhy here, the availability requirement is king. Integrity is a close second, as we want \\nto make sure that data that the OT systems and operators are making decisions on is \\nfree from error or manipulation. Confidentiality is hardly a major concern in a typical \\nOT environment, other than maybe with some historical data stored in a database or \\nin log files on a server or PC. This is because by the time the data is used, it is pretty \\nmuch worthless already; though as I said, stored production data, recipes, and—in some \\ncases—the control applications that are stored on storage media do have some value, and \\ntherefore the C in the CIA triad should not be completely ignored.\\nThe opportunities\\nWhy did IT and OT convergence occur? Wouldn't it make much more sense to keep the \\ntwo separated? Yes—from a security perspective, it would definitely make sense to keep \\nthings as separate as possible. However, from a business perspective, having accurate, \\non-the-fly, and relevant data coming from the OT environment makes a lot of sense. Such \\ninformation allows tighter production scheduling, can decrease the amount of inventory \\nthat needs to be held on site, helps cost calculation, and provides many more logistical \\nadvantages. Modern ERP and MES systems rely on input and information from both the \\nproduction and the enterprise side of a business. Those reasons—and many more—have \\ndriven the convergence of IT and OT systems. \\nThe risk\\nAs stated earlier in this chapter, the ICS (the OT environment) was originally built with, \\nand around, proprietary devices, equipment, and networking media and protocols, \\nwithout security in mind. Just about every vendor had their own way of doing things, and \\nevery one of them had a different way of configuring, operating, and maintaining their \\nsetup. This proprietary behavior did not work well with the whole IT/OT convergence \\ndemand, and slowly ICS equipment vendors started adhering to a common set of \\nstandards—namely, the widely used networking protocols Ethernet, Internet Protocol \\n(IP), Transport Control Protocol (TCP), and the User Datagram Protocol (UDP)—to \\nrun their controls and automation protocols over. \\n\", '']\n"
     ]
    }
   ],
   "source": [
    "test = extract_pdf_content(BOOK_PDF, 43, 44)\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a document object\n",
    "doc = fitz.open(BOOK_PDF)\n",
    "\n",
    "content_of_pdf = \"\"\n",
    "block_dict = {}\n",
    "\n",
    "\n",
    "#Iterate over all pages in the documents\n",
    "for i in range(doc.page_count):\n",
    "#for i in range(0,100):\n",
    "  page = doc.load_page(i)\n",
    "  file_dict = page.get_text('dict') # Get the page dictionary\n",
    "  block = file_dict['blocks'] # Get the block information\n",
    "  block_dict[i] = block\n",
    "  # read text and print it\n",
    "  text = page.get_text()\n",
    "  #Add the text to a string to be used in the prompt\n",
    "  content_of_pdf = content_of_pdf + text\n",
    "\n",
    "  ### IMAGES ###\n",
    "  # Extract all the images on the page and save the images\n",
    "  for i in page.get_images(full=True):\n",
    "    xref = i[0]\n",
    "    base_image = doc.extract_image(xref)\n",
    "    image_bytes = base_image[\"image\"]\n",
    "    image = fitz.Pixmap(doc, xref)\n",
    "    with open(f'{PATH}/image_{xref}.png', 'wb') as f:\n",
    "      f.write(image.tobytes())\n",
    "\n",
    "  ## TABLES ##\n",
    "  # Extract all the tables on the page and save the tables\n",
    "  tabs = page.find_tables()  # detect the tables\n",
    "  for i,tab in enumerate(tabs):  # iterate over all tables\n",
    "      print(f\"Table {i} column names: {tab.header.names}, external: {tab.header.external}\")\n",
    "      tab = tabs[i]\n",
    "      df = tab.to_pandas()\n",
    "      #Add the table to a string to be used in the prompt\n",
    "      content_of_pdf += df.to_string()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make a function out of that\n",
    "spans = pd.DataFrame(columns=['xmin', 'ymin', 'xmax', 'ymax', 'text', 'tag'])\n",
    "rows = []\n",
    "for page_num, blocks in block_dict.items():\n",
    "    for block in blocks:\n",
    "        if block['type'] == 0:\n",
    "            for line in block['lines']:\n",
    "                for span in line['spans']:\n",
    "                    xmin, ymin, xmax, ymax = list(span['bbox'])\n",
    "                    font_size = span['size']\n",
    "                    text = unidecode(span['text'])\n",
    "                    span_font = span['font']\n",
    "                    is_bold = False\n",
    "                    if \"bold\" in span_font.lower():\n",
    "                        is_bold = True\n",
    "                    if text.replace(\" \",\"\") !=  \"\":\n",
    "                        rows.append((xmin, ymin, xmax, ymax, text, is_bold, span_font, font_size, page_num))\n",
    "                        span_df = pd.DataFrame(rows, columns=['xmin','ymin','xmax','ymax', 'text','is_bold','span_font', 'font_size', 'page_num'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find text with table of content in span_df\n",
    "toc = span_df[span_df['text'].str.contains(\"table of content\", case=False)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(content_of_pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_text = \"\"\"You are an assistant tasked with summarizing texts. \\ \n",
    "Give a concise summary of the text. Text chunk: {element} \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = WORKSPACE_DIC + \"/Phi/Phi3/Phi-3-mini-4k-instruct-q4.gguf\"\n",
    "llm = LlamaCpp(\n",
    "    model_path= model_path,\n",
    "    n_gpu_layers=-1,\n",
    "    n_batch=4096,\n",
    "    n_ctx=4096,\n",
    "    temperature=1,\n",
    "    top_p=1,\n",
    "    max_tokens = 5000,\n",
    "    #callback_manager=callback_manager,\n",
    "    verbose=True,  # Verbose is required to pass to the callback manager\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = PromptTemplate.from_template(PROMPT)\n",
    "\n",
    "#Create text splitter to split the text into chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1024,\n",
    "    chunk_overlap=128,\n",
    ")\n",
    "\n",
    "# Split the text into chunks\n",
    "texts = text_splitter.split_text(content_of_pdf)\n",
    "\n",
    "prompt = PromptTemplate.from_template(prompt_text)\n",
    "\n",
    "summarize_chain = {\"element\": lambda x: x} | prompt | llm | StrOutputParser()\n",
    "\n",
    "text_summaries = summarize_chain.batch(texts, {\"max_concurrency\": 50})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the summaries to a file\n",
    "with open('summaries.txt', 'w') as f:\n",
    "    for item in text_summaries:\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the summaries from the file\n",
    "with open('summaries.txt', 'r') as f:\n",
    "    text_summaries = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_function = SentenceTransformerEmbeddings(model_name= \"sentence-transformers/all-mpnet-base-v2\")\n",
    "\n",
    "db = Chroma.from_texts(text_summaries, embedding_function)\n",
    "\n",
    "retriever = db.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 6})\n",
    "\n",
    "print(retriever)\n",
    "\n",
    "template2 = \"\"\"Answer the question based only on the following context, which can include text and tables:\n",
    "{context}\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "template = \"\"\"Create multiple choice question in one of the following format:\n",
    "Question: Which two options are the best reasons to use an IPV4 private IP space? (Choose two.)\n",
    "A. to enable intra-enterprise communication\n",
    "B. to implement NAT\n",
    "C. to connect applications\n",
    "D. to conserve global address space\n",
    "E. to manage routing overhead\n",
    "Answer: AD\n",
    "\n",
    "Question: The corporate security policy requires multiple elements to be matched in an authorization policy. Which elements can be combined to meet the requirement?\n",
    "A. Device registration status and device activation status\n",
    "B. Network access device and time condition\n",
    "C. User credentials and server certificate\n",
    "D. Built-in profile and custom profile\n",
    "Answer: B\n",
    "\n",
    "using the following context:\n",
    "{context}\n",
    "\"\"\"\n",
    "\n",
    "#prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "# Retrieve and generate using the relevant snippets of the blog.\n",
    "retriever = db.as_retriever()\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "rag_chain.invoke(\"\"\"Create multiple choice question in one in the following format out of the provided context\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(llm_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
