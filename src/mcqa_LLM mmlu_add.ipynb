{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes\n",
    "\n",
    "### Dataset MMLU Computer Security:\n",
    "* https://huggingface.co/datasets/cais/mmlu/viewer/computer_security/test\n",
    "\n",
    "### Big Mistake in Prompt:\n",
    "**Added the \"\"\" after a linebreak e.g.** <br>\n",
    "Anwser: <br>\n",
    "\"\"\"<br>\n",
    "**Correct way:<br>**\n",
    "Anwser:\"\"\"\n",
    "\n",
    "## HELM  implementation: \n",
    "* Max_output tokens to restrict the possible outputs to the max number of answers possibilities\n",
    "* Temperature = 0\n",
    "* Joint strategy (all answer choices are presented at once)\n",
    "* Short Introduction: The following are multiple choice questions (with answers) about computer security.\n",
    "* (Paper: https://arxiv.org/pdf/2211.09110.pdf)\n",
    "\n",
    "## HELM / Paper Imprreovements:\n",
    "* Sampling --> std, mean min / max accuracy\n",
    "\n",
    "# CCNA 201-301 - 5 Shot like HELM with Answer format: Answer: ABC or Answer: A <br>\n",
    "### Oberservations Phi:\n",
    "* Output of Phi-Model always empty, similiar config as mmlu (temp=0, max_output_token = 2), by increasing temp the result of Phi is better but still not close to the other models<br>\n",
    "* Also have to increase the Max Output Tokens otherwise only \\n as response\n",
    "* Possible approach: Increasing temp and output_tokens, regex pattern that searchs for string in responses\n",
    "### Oberservations Llama 2:\n",
    "* LLama 2 results are much worse in comp. to single shot with Correct Answer: ['A', 'B'] and temp =0.7 and no limit to output tokens\n",
    "\n",
    "\n",
    "## New \n",
    "\n",
    "* Yi, Llama 1, Llama 2 (nicht uncensored), Mixtral, Phi-2 --> Für MMLU\n",
    "* Prompt without whitespace --> extra \n",
    "* Ungeshuffeld vs HELM Grafik --> HELM vs unsere\n",
    "* Shuffle (min-max) vs nicht shuffeln\n",
    "* Dokumentieren --> Prompt, Changes Correct Answer Helm implementierung\n",
    "* Folien für Präsentation --> Implementierung, Ergebnisse (MMLU ähnlich wie HELM) --> , mit mehr Tokens CCNA Paper (Questionsbank nicht veröffentlicht) --> Weg Cisco (350-701 SCOR), Vetgleich zum Paper\n",
    "* Alles Dokumentieren\n",
    "* **How many points to pass? --> Horizontale** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from templates import *\n",
    "\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain_community.llms import LlamaCpp\n",
    "from langchain.callbacks.manager import CallbackManager\n",
    "import pandas as pd\n",
    "from langchain import PromptTemplate\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "import random\n",
    "import warnings\n",
    "import numpy as np\n",
    "import json\n",
    "warnings.filterwarnings('ignore')\n",
    "#Set the output limit to inf\n",
    "#pd.set_option('display.max_columns', None)\n",
    "#pd.set_option('display.max_rows', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = { #\"Mixtral-8x-7b\": \"../models/mixtral-8x7b-instruct-v0.1.Q4_K_M.gguf\",\n",
    "               \"Phi-2\": \"../models/phi-2.Q5_K_M.gguf\",\n",
    "               #\"Llama2-70b\": \"../models/llama2_70b_chat_uncensored.Q5_K_M.gguf\",\n",
    "               #\"Yi-34b\": \"../models/yi-34b-200k.Q5_K_M.gguf\",\n",
    "               #\"Dolphin-2.5\": \"../models/dolphin-2.5-mixtral-8x7b.Q5_K_M.gguf\",\n",
    "              }\n",
    "\n",
    "########### Set the model parameters here ############\n",
    "\n",
    "#Parameter for changing the temperature of the model\n",
    "TEMPERATURE = 0\n",
    "\n",
    "#Parameter for max output tokens (for MMLU choose 1, since only Single choice)\n",
    "\n",
    "MAX_OUTPUT_TOKENS = 1\n",
    "\n",
    "########### Set the model parameters here ############\n",
    "\n",
    "\n",
    "#Sampling rate determines how often a question is asked again if the answer format is wrong\n",
    "MAX_SAMPLING_RATE = 5\n",
    "\n",
    "#Set to 1 if you dont want to shuffle\n",
    "NUM_OF_SHUFFLES = 5\n",
    "\n",
    "\n",
    "########### Set the names for result / evaluation files here ############\n",
    "\n",
    "#Set run name\n",
    "RUN_NAME = \"5_Shot_201_301_CCNA\"\n",
    "\n",
    "#Set output file name\n",
    "OUTPUT_EVALUATION = \"../results/5_Shot_201_301_CCNA/llm_5_Shot_201_301.pkl\"\n",
    "\n",
    "#Filename output evaluation detailed\n",
    "OUTPUT_EVALUATION_DETAILED = \"../results/5_Shot_201_301_CCNA/llm_prob_result_detailed_201_301_CCNA_5_Shot.pkl\"\n",
    "\n",
    "#Set filename of json file\n",
    "OUTPUT_EVALUATION_JSON = \"../results/5_Shot_201_301_CCNA/llm_prob_result_201_301_CCNA_5_Shot.json\"\n",
    "\n",
    "########### Set the names for result files here ############\n",
    "\n",
    "\n",
    "########### Set the questionsbank here ############\n",
    "#Set the questionsbank\n",
    "#QUESTIONS_BANK = \"../data/201-301-CCNA.parquet\" ##CCNA\n",
    "QUESTIONS_BANK = \"../data/201-301-CCNA.parquet\" ##CCNA\n",
    "########### Set the questionsbank here ############\n",
    "\n",
    "########### Set the prompt template here ############\n",
    "PROMPT_TEMPLATE = FEW_SHOT_TEMPLATE_MMLU\n",
    "########### Set the prompt template here ############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the parameters as a JSON file\n",
    "parameters = {\n",
    "    \"RUN_NAME\": RUN_NAME,  # Ersetzen Sie durch den tatsächlichen Wert\n",
    "    \"QUESTION_BANK\": QUESTIONS_BANK,  # Ersetzen Sie durch den tatsächlichen Wert\n",
    "    \"MAX_SAMPLING_RATE\": MAX_SAMPLING_RATE,  # Ersetzen Sie durch den tatsächlichen Wert\n",
    "    \"NUM_OF_SHUFFLES\": NUM_OF_SHUFFLES,  # Ersetzen Sie durch den tatsächlichen Wert\n",
    "    \"FEW_SHOT_TEMPLATE\": PROMPT_TEMPLATE,  # Ersetzen Sie durch den tatsächlichen Wert\n",
    "    \"TEMPERATURE\": TEMPERATURE,  # Ersetzen Sie durch den tatsächlichen Wert\n",
    "    \"MAX_TOKENS\": MAX_OUTPUT_TOKENS  # Ersetzen Sie durch den tatsächlichen Wert\n",
    "}\n",
    "\n",
    "# Speichern Sie das Wörterbuch als JSON-Datei\n",
    "with open(OUTPUT_EVALUATION_JSON, 'w') as f:\n",
    "    json.dump(parameters, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_answer(answer):\n",
    "    \"\"\"Extracts the correct answers from the provided answer string.\n",
    "\n",
    "    Args:\n",
    "        answer: The answer string to extract the correct answers from.\n",
    "\n",
    "    Returns:\n",
    "        A list of correct answers (e.g., ['A', 'B']) if found, otherwise None. \n",
    "    \"\"\"\n",
    "    print(repr(answer))\n",
    "    answer = re.sub(r'[\\s\\n.,]', '', answer)\n",
    "    pattern = re.compile(r'^[A-Z,]*$')\n",
    "    if re.match(pattern, answer):\n",
    "        if ',' in answer:\n",
    "            return None\n",
    "        else:\n",
    "            return list(answer)\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def compare_answers(answerLLM, answer_exam):\n",
    "    \"\"\"Compares the extracted correct answers with the answers in answer_exam.\n",
    "\n",
    "    Keyword arguments:\n",
    "    answerLLM -- the list of answers extracted from the LLM answer\n",
    "    answer_exam -- list of answers from the exam\n",
    "    \"\"\"\n",
    "    # Convert answer_exam_list from letters to numbers\n",
    "    answerLLM = [ord(answer) - 65 for answer in answerLLM]\n",
    "\n",
    "    # Get number of correct answers in the exam\n",
    "    num_of_correct_exam_answers = len(answer_exam)\n",
    "\n",
    "    # Convert both lists to sets for efficient comparison\n",
    "    answer_LLM_set = set(answerLLM)\n",
    "    answer_exam_set = set(answer_exam)\n",
    "\n",
    "    # Calculate the count of matching answers\n",
    "    number_of_correct_llm_answers = len(answer_LLM_set.intersection(answer_exam_set))\n",
    "\n",
    "    # Check if the number of answers given by the LLM is greater than the number of correct answers\n",
    "    too_many_answ_given = False\n",
    "    if len(answer_LLM_set) > num_of_correct_exam_answers:\n",
    "        too_many_answ_given = True\n",
    "\n",
    "    # Return a dictionary with the matching count and the number of correct answers\n",
    "    return number_of_correct_llm_answers, too_many_answ_given\n",
    "\n",
    "def format_choices_for_llm(choices):\n",
    "    #Define the letters for the choices\n",
    "    letters = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J']\n",
    "    \n",
    "    # Erstellen Sie den formatierten String\n",
    "    formatted_choices = '\\n'.join(f'{letters[i]}. {choice}' for i, choice in enumerate(choices))\n",
    "    \n",
    "    return formatted_choices\n",
    "\n",
    "def evaluation_sampling(llm_answer, exam_Answers, num_of_correct_answer):\n",
    "    \"\"\"Analyse the answer given by the LLM and compare it with the exam answers.\n",
    "\n",
    "    Keyword arguments:\n",
    "    llm_answer -- the answer string given by the LLM\n",
    "    exam_Answers -- the list of answers from the exam\n",
    "    \"\"\"\n",
    "\n",
    "    answerLLM = extract_answer(llm_answer)\n",
    "    if answerLLM is not None:\n",
    "        num_of_correct_llm_Answers, too_many_answ = compare_answers(answerLLM, exam_Answers)\n",
    "        if num_of_correct_llm_Answers == num_of_correct_answer and too_many_answ == False:\n",
    "            answered_correctly = True\n",
    "        else:\n",
    "            answered_correctly = False \n",
    "        return num_of_correct_llm_Answers, answerLLM, too_many_answ, answered_correctly\n",
    "    else:\n",
    "         return -1\n",
    "\n",
    "\n",
    "def evaluation(llm_output_dataframe):\n",
    "\n",
    "    # Compute the number of total questions for each model\n",
    "    number_of_questions = llm_output_dataframe.groupby('Model')['QuestionIndex'].count()\n",
    "    \n",
    "    #Number of fully correct answers given by the LLM\n",
    "    correctly_answered = llm_output_dataframe.groupby('Model')['Answered_Correctly'].sum()\n",
    "\n",
    "    #Number of incorrect answers given by the LLM\n",
    "    incorrectly_answered = number_of_questions - correctly_answered\n",
    "\n",
    "    #Amount of correct answers in the exam\n",
    "    amount_correcct_exam_answers = llm_output_dataframe.groupby('Model')['NumberOfCorrectExamAnswers'].sum()\n",
    "\n",
    "    #Amount of correct answers given by the LLM even if not fully correct\n",
    "    amount_correcct_llm_answers = llm_output_dataframe.groupby('Model')['NumberOfCorrectLLMAnswers'].sum()\n",
    "    \n",
    "    #Calculation of Accuracy and Recall and f1 score\n",
    "    accuracy = correctly_answered / number_of_questions\n",
    "    accuracy_partial = amount_correcct_llm_answers / amount_correcct_exam_answers\n",
    "\n",
    "\n",
    "    results_df = pd.DataFrame({\n",
    "        'Number of Questions': number_of_questions,\n",
    "        'Correctly Answered': correctly_answered,\n",
    "        'Incorrectly Answered': incorrectly_answered,\n",
    "        'Accuracy': accuracy,\n",
    "        'Accuracy Partial': accuracy_partial,\n",
    "    })\n",
    "\n",
    "    results_df = results_df.reset_index()\n",
    "\n",
    "    return results_df\n",
    "\n",
    "\n",
    "def plot_evaluation(evaluation_df):\n",
    "    \"\"\"\n",
    "    Plots evaluation metrics from a DataFrame containing columns:\n",
    "        - 'Model'\n",
    "        - 'Accuracy Mean', 'Accuracy Min', 'Accuracy Max'\n",
    "        - 'Accuracy Partial Mean', 'Accuracy Partial Min', 'Accuracy Partial Max'\n",
    "    \"\"\"\n",
    "\n",
    "    # Define a list of colors for the models\n",
    "    colors = ['b', 'g', 'r', 'c', 'm', 'y', 'k']\n",
    "\n",
    "    # Define bar width\n",
    "    bar_width = 0.5  # Increase bar width for thicker bars\n",
    "\n",
    "    # --- Subplot 1: Accuracy ---\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "    for i, model in enumerate(evaluation_df['Model']):\n",
    "        bars = axs[0].bar(i + bar_width * i, evaluation_df.loc[i, 'Accuracy Mean'], bar_width, \n",
    "                   yerr=[[abs(evaluation_df.loc[i, 'Accuracy Mean'] - evaluation_df.loc[i, 'Accuracy Min'])], [abs(evaluation_df.loc[i, 'Accuracy Max'] - evaluation_df.loc[i, 'Accuracy Mean'])]],\n",
    "                   label=model, color=colors[i % len(colors)], capsize=5)\n",
    "\n",
    "    axs[0].set_ylabel('Accuracy (%)')\n",
    "    axs[0].set_title('Accuracy Mean with Error Bars (Max and Min)', fontsize=12)\n",
    "    axs[0].set_xticks([i + bar_width * i for i in range(len(evaluation_df['Model']))])\n",
    "    axs[0].set_xticklabels(evaluation_df['Model'], rotation=45, ha='right', fontsize=10)\n",
    "    axs[0].legend()\n",
    "    axs[0].set_ylim([0, 1])\n",
    "    axs[0].yaxis.set_major_locator(mtick.MultipleLocator(0.1))\n",
    "    axs[0].yaxis.set_major_formatter(mtick.PercentFormatter(1.0))\n",
    "    axs[0].grid(True, linestyle='dotted', axis='y')\n",
    "\n",
    "    # --- Subplot 2: Partial Accuracy ---\n",
    "    for i, model in enumerate(evaluation_df['Model']):\n",
    "        bars = axs[1].bar(i + bar_width * i, evaluation_df.loc[i, 'Accuracy Partial Mean'], bar_width,\n",
    "                   yerr=[[abs(evaluation_df.loc[i, 'Accuracy Partial Mean'] - evaluation_df.loc[i, 'Accuracy Partial Min'])], [abs(evaluation_df.loc[i, 'Accuracy Partial Max'] - evaluation_df.loc[i, 'Accuracy Partial Mean'])]],\n",
    "                   label=model, color=colors[i % len(colors)], capsize=5)\n",
    "\n",
    "    axs[1].set_ylabel('Accuracy Partial (%)')\n",
    "    axs[1].set_title('Accuracy Partial Mean with Error Bars (Max and Min)', fontsize=12)\n",
    "    axs[1].set_xticks([i + bar_width * i for i in range(len(evaluation_df['Model']))])\n",
    "    axs[1].set_xticklabels(evaluation_df['Model'], rotation=45, ha='right', fontsize=10)\n",
    "    axs[1].legend()\n",
    "    axs[1].set_ylim([0, 1])\n",
    "    axs[1].yaxis.set_major_locator(mtick.MultipleLocator(0.1))\n",
    "    axs[1].yaxis.set_major_formatter(mtick.PercentFormatter(1.0))\n",
    "    axs[1].grid(True, linestyle='dotted', axis='y')\n",
    "\n",
    "    fig.tight_layout(pad=1.2)  # Decrease padding for closer plots\n",
    "    plt.show()\n",
    "\n",
    "def calculate_model_statistics(df):\n",
    "    \"\"\"\n",
    "    Calculates statistics for each model in the DataFrame.\n",
    "    \n",
    "    Args:\n",
    "    df (DataFrame): Input DataFrame containing evaluation metrics for different models.\n",
    "    \n",
    "    Returns:\n",
    "    DataFrame: New DataFrame containing calculated statistics for each model.\n",
    "    \"\"\"\n",
    "    model_stats = []\n",
    "    for model, group_df in df.groupby('Model'):\n",
    "        model_stat = {\n",
    "            'Model': model,\n",
    "            'Accuracy Mean': group_df['Accuracy'].mean(),\n",
    "            'Accuracy Max': group_df['Accuracy'].max(),\n",
    "            'Accuracy Min': group_df['Accuracy'].min(),\n",
    "            'Accuracy STD': group_df['Accuracy'].std(),\n",
    "            'Accuracy Partial Mean': group_df['Accuracy Partial'].mean(),\n",
    "            'Accuracy Partial Max': group_df['Accuracy Partial'].max(),\n",
    "            'Accuracy Partial Min': group_df['Accuracy Partial'].min(),\n",
    "            'Accuracy Partial STD': group_df['Accuracy Partial'].std()\n",
    "        }\n",
    "        model_stats.append(model_stat)\n",
    "    \n",
    "    return pd.DataFrame(model_stats)\n",
    "\n",
    "\n",
    "def shuffle_choices_and_update_answer(choices, answer):\n",
    "    # Erstellen Sie eine Liste von Indizes und mischen Sie sie\n",
    "    indices = list(range(len(choices)))\n",
    "    random.shuffle(indices)\n",
    "    \n",
    "    # Verwenden Sie die gemischten Indizes, um die Auswahlmöglichkeiten und die Antwort zu aktualisieren\n",
    "    shuffled_choices = [choices[i] for i in indices]\n",
    "    updated_answer = [indices.index(a) for a in answer]  # Entfernen Sie +1, um 0-basierte Indizes zu verwenden\n",
    "    \n",
    "    return shuffled_choices, updated_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 20 key-value pairs and 325 tensors from ../models/phi-2.Q5_K_M.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = phi2\n",
      "llama_model_loader: - kv   1:                               general.name str              = Phi2\n",
      "llama_model_loader: - kv   2:                        phi2.context_length u32              = 2048\n",
      "llama_model_loader: - kv   3:                      phi2.embedding_length u32              = 2560\n",
      "llama_model_loader: - kv   4:                   phi2.feed_forward_length u32              = 10240\n",
      "llama_model_loader: - kv   5:                           phi2.block_count u32              = 32\n",
      "llama_model_loader: - kv   6:                  phi2.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv   7:               phi2.attention.head_count_kv u32              = 32\n",
      "llama_model_loader: - kv   8:          phi2.attention.layer_norm_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv   9:                  phi2.rope.dimension_count u32              = 32\n",
      "llama_model_loader: - kv  10:                          general.file_type u32              = 17\n",
      "llama_model_loader: - kv  11:               tokenizer.ggml.add_bos_token bool             = false\n",
      "llama_model_loader: - kv  12:                       tokenizer.ggml.model str              = gpt2\n",
      "llama_model_loader: - kv  13:                      tokenizer.ggml.tokens arr[str,51200]   = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
      "llama_model_loader: - kv  14:                  tokenizer.ggml.token_type arr[i32,51200]   = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
      "llama_model_loader: - kv  15:                      tokenizer.ggml.merges arr[str,50000]   = [\"Ġ t\", \"Ġ a\", \"h e\", \"i n\", \"r e\",...\n",
      "llama_model_loader: - kv  16:                tokenizer.ggml.bos_token_id u32              = 50256\n",
      "llama_model_loader: - kv  17:                tokenizer.ggml.eos_token_id u32              = 50256\n",
      "llama_model_loader: - kv  18:            tokenizer.ggml.unknown_token_id u32              = 50256\n",
      "llama_model_loader: - kv  19:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:  195 tensors\n",
      "llama_model_loader: - type q5_K:   81 tensors\n",
      "llama_model_loader: - type q6_K:   49 tensors\n",
      "llm_load_vocab: mismatch in special tokens definition ( 910/51200 vs 944/51200 ).\n",
      "llm_load_print_meta: format           = GGUF V3 (latest)\n",
      "llm_load_print_meta: arch             = phi2\n",
      "llm_load_print_meta: vocab type       = BPE\n",
      "llm_load_print_meta: n_vocab          = 51200\n",
      "llm_load_print_meta: n_merges         = 50000\n",
      "llm_load_print_meta: n_ctx_train      = 2048\n",
      "llm_load_print_meta: n_embd           = 2560\n",
      "llm_load_print_meta: n_head           = 32\n",
      "llm_load_print_meta: n_head_kv        = 32\n",
      "llm_load_print_meta: n_layer          = 32\n",
      "llm_load_print_meta: n_rot            = 32\n",
      "llm_load_print_meta: n_embd_head_k    = 80\n",
      "llm_load_print_meta: n_embd_head_v    = 80\n",
      "llm_load_print_meta: n_gqa            = 1\n",
      "llm_load_print_meta: n_embd_k_gqa     = 2560\n",
      "llm_load_print_meta: n_embd_v_gqa     = 2560\n",
      "llm_load_print_meta: f_norm_eps       = 1.0e-05\n",
      "llm_load_print_meta: f_norm_rms_eps   = 0.0e+00\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 10240\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 10000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_yarn_orig_ctx  = 2048\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: model type       = 3B\n",
      "llm_load_print_meta: model ftype      = Q5_K - Medium\n",
      "llm_load_print_meta: model params     = 2.78 B\n",
      "llm_load_print_meta: model size       = 1.93 GiB (5.96 BPW) \n",
      "llm_load_print_meta: general.name     = Phi2\n",
      "llm_load_print_meta: BOS token        = 50256 '<|endoftext|>'\n",
      "llm_load_print_meta: EOS token        = 50256 '<|endoftext|>'\n",
      "llm_load_print_meta: UNK token        = 50256 '<|endoftext|>'\n",
      "llm_load_print_meta: LF token         = 128 'Ä'\n",
      "llm_load_tensors: ggml ctx size =    0.37 MiB\n",
      "llm_load_tensors: offloading 32 repeating layers to GPU\n",
      "llm_load_tensors: offloading non-repeating layers to GPU\n",
      "llm_load_tensors: offloaded 33/33 layers to GPU\n",
      "llm_load_tensors:        CPU buffer size =    85.94 MiB\n",
      "llm_load_tensors:      CUDA0 buffer size =   953.93 MiB\n",
      "llm_load_tensors:      CUDA1 buffer size =   935.08 MiB\n",
      "...........................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 1100\n",
      "llama_new_context_with_model: freq_base  = 10000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "llama_kv_cache_init:      CUDA0 KV buffer size =   182.62 MiB\n",
      "llama_kv_cache_init:      CUDA1 KV buffer size =   161.13 MiB\n",
      "llama_new_context_with_model: KV self size  =  343.75 MiB, K (f16):  171.88 MiB, V (f16):  171.88 MiB\n",
      "llama_new_context_with_model:  CUDA_Host input buffer size   =    14.31 MiB\n",
      "llama_new_context_with_model:      CUDA0 compute buffer size =   221.98 MiB\n",
      "llama_new_context_with_model:      CUDA1 compute buffer size =   242.00 MiB\n",
      "llama_new_context_with_model:  CUDA_Host compute buffer size =    11.00 MiB\n",
      "llama_new_context_with_model: graph splits (measure): 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>QuestionIndex</th>\n",
       "      <th>SamplingIndex</th>\n",
       "      <th>NumberOfCorrectLLMAnswers</th>\n",
       "      <th>NumberOfCorrectExamAnswers</th>\n",
       "      <th>Ratio</th>\n",
       "      <th>LLM_Answer</th>\n",
       "      <th>Exam_Answers</th>\n",
       "      <th>Answered_Correctly</th>\n",
       "      <th>Too_Many_answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Phi-2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[0, 3]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Phi-2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Phi-2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Phi-2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[2]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Phi-2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[2]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>Phi-2</td>\n",
       "      <td>199</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>Phi-2</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[3]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>Phi-2</td>\n",
       "      <td>201</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[3]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>Phi-2</td>\n",
       "      <td>202</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[2]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>Phi-2</td>\n",
       "      <td>203</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[3]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>204 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Model QuestionIndex SamplingIndex NumberOfCorrectLLMAnswers  \\\n",
       "0    Phi-2             0             0                         0   \n",
       "1    Phi-2             1             0                         0   \n",
       "2    Phi-2             2             0                         0   \n",
       "3    Phi-2             3             0                         0   \n",
       "4    Phi-2             4             0                         0   \n",
       "..     ...           ...           ...                       ...   \n",
       "199  Phi-2           199             0                         0   \n",
       "200  Phi-2           200             0                         0   \n",
       "201  Phi-2           201             0                         0   \n",
       "202  Phi-2           202             0                         0   \n",
       "203  Phi-2           203             0                         0   \n",
       "\n",
       "    NumberOfCorrectExamAnswers  Ratio LLM_Answer Exam_Answers  \\\n",
       "0                            2    0.0         []       [0, 3]   \n",
       "1                            1    0.0         []          [0]   \n",
       "2                            1    0.0         []          [0]   \n",
       "3                            1    0.0         []          [2]   \n",
       "4                            1    0.0         []          [2]   \n",
       "..                         ...    ...        ...          ...   \n",
       "199                          1    0.0         []          [0]   \n",
       "200                          1    0.0         []          [3]   \n",
       "201                          1    0.0         []          [3]   \n",
       "202                          1    0.0         []          [2]   \n",
       "203                          1    0.0         []          [3]   \n",
       "\n",
       "    Answered_Correctly Too_Many_answers  \n",
       "0                False            False  \n",
       "1                False            False  \n",
       "2                False            False  \n",
       "3                False            False  \n",
       "4                False            False  \n",
       "..                 ...              ...  \n",
       "199              False            False  \n",
       "200              False            False  \n",
       "201              False            False  \n",
       "202              False            False  \n",
       "203              False            False  \n",
       "\n",
       "[204 rows x 10 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of Questions</th>\n",
       "      <th>Correctly Answered</th>\n",
       "      <th>Incorrectly Answered</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Accuracy Partial</th>\n",
       "      <th>Model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>204</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Phi-2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Number of Questions Correctly Answered Incorrectly Answered Accuracy  \\\n",
       "0                 204                  0                  204      0.0   \n",
       "\n",
       "  Accuracy Partial  Model  \n",
       "0              0.0  Phi-2  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>QuestionIndex</th>\n",
       "      <th>SamplingIndex</th>\n",
       "      <th>NumberOfCorrectLLMAnswers</th>\n",
       "      <th>NumberOfCorrectExamAnswers</th>\n",
       "      <th>Ratio</th>\n",
       "      <th>LLM_Answer</th>\n",
       "      <th>Exam_Answers</th>\n",
       "      <th>Answered_Correctly</th>\n",
       "      <th>Too_Many_answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Phi-2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[3, 0]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Phi-2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Phi-2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Phi-2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Phi-2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[3]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>Phi-2</td>\n",
       "      <td>199</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>Phi-2</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[3]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>Phi-2</td>\n",
       "      <td>201</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[3]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>Phi-2</td>\n",
       "      <td>202</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[3]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>Phi-2</td>\n",
       "      <td>203</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>204 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Model QuestionIndex SamplingIndex NumberOfCorrectLLMAnswers  \\\n",
       "0    Phi-2             0             0                         0   \n",
       "1    Phi-2             1             0                         0   \n",
       "2    Phi-2             2             0                         0   \n",
       "3    Phi-2             3             0                         0   \n",
       "4    Phi-2             4             0                         0   \n",
       "..     ...           ...           ...                       ...   \n",
       "199  Phi-2           199             0                         0   \n",
       "200  Phi-2           200             0                         0   \n",
       "201  Phi-2           201             0                         0   \n",
       "202  Phi-2           202             0                         0   \n",
       "203  Phi-2           203             0                         0   \n",
       "\n",
       "    NumberOfCorrectExamAnswers  Ratio LLM_Answer Exam_Answers  \\\n",
       "0                            2    0.0         []       [3, 0]   \n",
       "1                            1    0.0         []          [0]   \n",
       "2                            1    0.0         []          [1]   \n",
       "3                            1    0.0         []          [0]   \n",
       "4                            1    0.0         []          [3]   \n",
       "..                         ...    ...        ...          ...   \n",
       "199                          1    0.0         []          [1]   \n",
       "200                          1    0.0         []          [3]   \n",
       "201                          1    0.0         []          [3]   \n",
       "202                          1    0.0         []          [3]   \n",
       "203                          1    0.0         []          [1]   \n",
       "\n",
       "    Answered_Correctly Too_Many_answers  \n",
       "0                False            False  \n",
       "1                False            False  \n",
       "2                False            False  \n",
       "3                False            False  \n",
       "4                False            False  \n",
       "..                 ...              ...  \n",
       "199              False            False  \n",
       "200              False            False  \n",
       "201              False            False  \n",
       "202              False            False  \n",
       "203              False            False  \n",
       "\n",
       "[204 rows x 10 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of Questions</th>\n",
       "      <th>Correctly Answered</th>\n",
       "      <th>Incorrectly Answered</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Accuracy Partial</th>\n",
       "      <th>Model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>204</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Phi-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>204</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Phi-2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Number of Questions Correctly Answered Incorrectly Answered Accuracy  \\\n",
       "0                 204                  0                  204      0.0   \n",
       "1                 204                  0                  204      0.0   \n",
       "\n",
       "  Accuracy Partial  Model  \n",
       "0              0.0  Phi-2  \n",
       "1              0.0  Phi-2  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n",
      "'\\n'\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 53\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m#Iterate over the maximum sampling rate\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index_sampling \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(MAX_SAMPLING_RATE):\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;66;03m# Invoke the chain with the question and choices              \u001b[39;00m\n\u001b[0;32m---> 53\u001b[0m     llm_answer \u001b[38;5;241m=\u001b[39m \u001b[43mchain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mExam_Question\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mquestion\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mExam_Choices\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mchoices\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m            \n\u001b[1;32m     54\u001b[0m     \u001b[38;5;66;03m# Check if the answer is in the expected format\u001b[39;00m\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m extract_answer(llm_answer) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     56\u001b[0m         \u001b[38;5;66;03m# Extract the correct answers from the LLM answer and analyse the answer\u001b[39;00m\n",
      "File \u001b[0;32m~/git/llm_test/.venv/lib/python3.10/site-packages/langchain_core/runnables/base.py:2053\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[0;34m(self, input, config)\u001b[0m\n\u001b[1;32m   2051\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   2052\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps):\n\u001b[0;32m-> 2053\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2054\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2055\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# mark each step as a child run\u001b[39;49;00m\n\u001b[1;32m   2056\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpatch_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2057\u001b[0m \u001b[43m                \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseq:step:\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2058\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2059\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2060\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[1;32m   2061\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/git/llm_test/.venv/lib/python3.10/site-packages/langchain_core/language_models/llms.py:235\u001b[0m, in \u001b[0;36mBaseLLM.invoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[1;32m    226\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;28minput\u001b[39m: LanguageModelInput,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    231\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    232\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m    233\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m--> 235\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcallbacks\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtags\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    240\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    241\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    242\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    244\u001b[0m         \u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    245\u001b[0m         \u001b[38;5;241m.\u001b[39mtext\n\u001b[1;32m    246\u001b[0m     )\n",
      "File \u001b[0;32m~/git/llm_test/.venv/lib/python3.10/site-packages/langchain_core/language_models/llms.py:530\u001b[0m, in \u001b[0;36mBaseLLM.generate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    522\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[1;32m    523\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    524\u001b[0m     prompts: List[PromptValue],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    527\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    528\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[1;32m    529\u001b[0m     prompt_strings \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_string() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[0;32m--> 530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_strings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/git/llm_test/.venv/lib/python3.10/site-packages/langchain_core/language_models/llms.py:703\u001b[0m, in \u001b[0;36mBaseLLM.generate\u001b[0;34m(self, prompts, stop, callbacks, tags, metadata, run_name, **kwargs)\u001b[0m\n\u001b[1;32m    687\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    688\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAsked to cache, but no cache found at `langchain.cache`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    689\u001b[0m         )\n\u001b[1;32m    690\u001b[0m     run_managers \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    691\u001b[0m         callback_manager\u001b[38;5;241m.\u001b[39mon_llm_start(\n\u001b[1;32m    692\u001b[0m             dumpd(\u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    701\u001b[0m         )\n\u001b[1;32m    702\u001b[0m     ]\n\u001b[0;32m--> 703\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    704\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mbool\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnew_arg_supported\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output\n\u001b[1;32m    707\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(missing_prompts) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/git/llm_test/.venv/lib/python3.10/site-packages/langchain_core/language_models/llms.py:567\u001b[0m, in \u001b[0;36mBaseLLM._generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    565\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m run_manager \u001b[38;5;129;01min\u001b[39;00m run_managers:\n\u001b[1;32m    566\u001b[0m         run_manager\u001b[38;5;241m.\u001b[39mon_llm_error(e, response\u001b[38;5;241m=\u001b[39mLLMResult(generations\u001b[38;5;241m=\u001b[39m[]))\n\u001b[0;32m--> 567\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    568\u001b[0m flattened_outputs \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[1;32m    569\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m manager, flattened_output \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(run_managers, flattened_outputs):\n",
      "File \u001b[0;32m~/git/llm_test/.venv/lib/python3.10/site-packages/langchain_core/language_models/llms.py:554\u001b[0m, in \u001b[0;36mBaseLLM._generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    544\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_generate_helper\u001b[39m(\n\u001b[1;32m    545\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    546\u001b[0m     prompts: List[\u001b[38;5;28mstr\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    550\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    551\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[1;32m    552\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    553\u001b[0m         output \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 554\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    555\u001b[0m \u001b[43m                \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    556\u001b[0m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    557\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;66;43;03m# TODO: support multiple run managers\u001b[39;49;00m\n\u001b[1;32m    558\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    559\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    560\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    561\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    562\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(prompts, stop\u001b[38;5;241m=\u001b[39mstop)\n\u001b[1;32m    563\u001b[0m         )\n\u001b[1;32m    564\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    565\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m run_manager \u001b[38;5;129;01min\u001b[39;00m run_managers:\n",
      "File \u001b[0;32m~/git/llm_test/.venv/lib/python3.10/site-packages/langchain_core/language_models/llms.py:1139\u001b[0m, in \u001b[0;36mLLM._generate\u001b[0;34m(self, prompts, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m   1136\u001b[0m new_arg_supported \u001b[38;5;241m=\u001b[39m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1137\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m prompt \u001b[38;5;129;01min\u001b[39;00m prompts:\n\u001b[1;32m   1138\u001b[0m     text \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m-> 1139\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1140\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m   1141\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(prompt, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1142\u001b[0m     )\n\u001b[1;32m   1143\u001b[0m     generations\u001b[38;5;241m.\u001b[39mappend([Generation(text\u001b[38;5;241m=\u001b[39mtext)])\n\u001b[1;32m   1144\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m LLMResult(generations\u001b[38;5;241m=\u001b[39mgenerations)\n",
      "File \u001b[0;32m~/git/llm_test/.venv/lib/python3.10/site-packages/langchain_community/llms/llamacpp.py:291\u001b[0m, in \u001b[0;36mLlamaCpp._call\u001b[0;34m(self, prompt, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    286\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstreaming:\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;66;03m# If streaming is enabled, we use the stream\u001b[39;00m\n\u001b[1;32m    288\u001b[0m     \u001b[38;5;66;03m# method that yields as they are generated\u001b[39;00m\n\u001b[1;32m    289\u001b[0m     \u001b[38;5;66;03m# and return the combined strings from the first choices's text:\u001b[39;00m\n\u001b[1;32m    290\u001b[0m     combined_text_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 291\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stream(\n\u001b[1;32m    292\u001b[0m         prompt\u001b[38;5;241m=\u001b[39mprompt,\n\u001b[1;32m    293\u001b[0m         stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[1;32m    294\u001b[0m         run_manager\u001b[38;5;241m=\u001b[39mrun_manager,\n\u001b[1;32m    295\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    296\u001b[0m     ):\n\u001b[1;32m    297\u001b[0m         combined_text_output \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m chunk\u001b[38;5;241m.\u001b[39mtext\n\u001b[1;32m    298\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m combined_text_output\n",
      "File \u001b[0;32m~/git/llm_test/.venv/lib/python3.10/site-packages/langchain_community/llms/llamacpp.py:344\u001b[0m, in \u001b[0;36mLlamaCpp._stream\u001b[0;34m(self, prompt, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    342\u001b[0m params \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_parameters(stop), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs}\n\u001b[1;32m    343\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient(prompt\u001b[38;5;241m=\u001b[39mprompt, stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[0;32m--> 344\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m part \u001b[38;5;129;01min\u001b[39;00m result:\n\u001b[1;32m    345\u001b[0m     logprobs \u001b[38;5;241m=\u001b[39m part[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchoices\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogprobs\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    346\u001b[0m     chunk \u001b[38;5;241m=\u001b[39m GenerationChunk(\n\u001b[1;32m    347\u001b[0m         text\u001b[38;5;241m=\u001b[39mpart[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchoices\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    348\u001b[0m         generation_info\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogprobs\u001b[39m\u001b[38;5;124m\"\u001b[39m: logprobs},\n\u001b[1;32m    349\u001b[0m     )\n",
      "File \u001b[0;32m~/git/llm_test/.venv/lib/python3.10/site-packages/llama_cpp/llama.py:888\u001b[0m, in \u001b[0;36mLlama._create_completion\u001b[0;34m(self, prompt, suffix, max_tokens, temperature, top_p, min_p, typical_p, logprobs, echo, stop, frequency_penalty, presence_penalty, repeat_penalty, top_k, stream, seed, tfs_z, mirostat_mode, mirostat_tau, mirostat_eta, model, stopping_criteria, logits_processor, grammar, logit_bias)\u001b[0m\n\u001b[1;32m    886\u001b[0m finish_reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlength\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    887\u001b[0m multibyte_fix \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 888\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate(\n\u001b[1;32m    889\u001b[0m     prompt_tokens,\n\u001b[1;32m    890\u001b[0m     top_k\u001b[38;5;241m=\u001b[39mtop_k,\n\u001b[1;32m    891\u001b[0m     top_p\u001b[38;5;241m=\u001b[39mtop_p,\n\u001b[1;32m    892\u001b[0m     min_p\u001b[38;5;241m=\u001b[39mmin_p,\n\u001b[1;32m    893\u001b[0m     typical_p\u001b[38;5;241m=\u001b[39mtypical_p,\n\u001b[1;32m    894\u001b[0m     temp\u001b[38;5;241m=\u001b[39mtemperature,\n\u001b[1;32m    895\u001b[0m     tfs_z\u001b[38;5;241m=\u001b[39mtfs_z,\n\u001b[1;32m    896\u001b[0m     mirostat_mode\u001b[38;5;241m=\u001b[39mmirostat_mode,\n\u001b[1;32m    897\u001b[0m     mirostat_tau\u001b[38;5;241m=\u001b[39mmirostat_tau,\n\u001b[1;32m    898\u001b[0m     mirostat_eta\u001b[38;5;241m=\u001b[39mmirostat_eta,\n\u001b[1;32m    899\u001b[0m     frequency_penalty\u001b[38;5;241m=\u001b[39mfrequency_penalty,\n\u001b[1;32m    900\u001b[0m     presence_penalty\u001b[38;5;241m=\u001b[39mpresence_penalty,\n\u001b[1;32m    901\u001b[0m     repeat_penalty\u001b[38;5;241m=\u001b[39mrepeat_penalty,\n\u001b[1;32m    902\u001b[0m     stopping_criteria\u001b[38;5;241m=\u001b[39mstopping_criteria,\n\u001b[1;32m    903\u001b[0m     logits_processor\u001b[38;5;241m=\u001b[39mlogits_processor,\n\u001b[1;32m    904\u001b[0m     grammar\u001b[38;5;241m=\u001b[39mgrammar,\n\u001b[1;32m    905\u001b[0m ):\n\u001b[1;32m    906\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m token \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_token_eos:\n\u001b[1;32m    907\u001b[0m         text \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdetokenize(completion_tokens)\n",
      "File \u001b[0;32m~/git/llm_test/.venv/lib/python3.10/site-packages/llama_cpp/llama.py:643\u001b[0m, in \u001b[0;36mLlama.generate\u001b[0;34m(self, tokens, top_k, top_p, min_p, typical_p, temp, repeat_penalty, reset, frequency_penalty, presence_penalty, tfs_z, mirostat_mode, mirostat_tau, mirostat_eta, penalize_nl, logits_processor, stopping_criteria, grammar)\u001b[0m\n\u001b[1;32m    641\u001b[0m \u001b[38;5;66;03m# Eval and sample\u001b[39;00m\n\u001b[1;32m    642\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 643\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    644\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m sample_idx \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_tokens:\n\u001b[1;32m    645\u001b[0m         token \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msample(\n\u001b[1;32m    646\u001b[0m             top_k\u001b[38;5;241m=\u001b[39mtop_k,\n\u001b[1;32m    647\u001b[0m             top_p\u001b[38;5;241m=\u001b[39mtop_p,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    661\u001b[0m             idx\u001b[38;5;241m=\u001b[39msample_idx,\n\u001b[1;32m    662\u001b[0m         )\n",
      "File \u001b[0;32m~/git/llm_test/.venv/lib/python3.10/site-packages/llama_cpp/llama.py:483\u001b[0m, in \u001b[0;36mLlama.eval\u001b[0;34m(self, tokens)\u001b[0m\n\u001b[1;32m    479\u001b[0m n_tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch)\n\u001b[1;32m    480\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch\u001b[38;5;241m.\u001b[39mset_batch(\n\u001b[1;32m    481\u001b[0m     batch\u001b[38;5;241m=\u001b[39mbatch, n_past\u001b[38;5;241m=\u001b[39mn_past, logits_all\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontext_params\u001b[38;5;241m.\u001b[39mlogits_all\n\u001b[1;32m    482\u001b[0m )\n\u001b[0;32m--> 483\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[38;5;66;03m# Save tokens\u001b[39;00m\n\u001b[1;32m    485\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_ids[n_past : n_past \u001b[38;5;241m+\u001b[39m n_tokens] \u001b[38;5;241m=\u001b[39m batch\n",
      "File \u001b[0;32m~/git/llm_test/.venv/lib/python3.10/site-packages/llama_cpp/_internals.py:309\u001b[0m, in \u001b[0;36m_LlamaContext.decode\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mctx \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m batch\u001b[38;5;241m.\u001b[39mbatch \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 309\u001b[0m return_code \u001b[38;5;241m=\u001b[39m \u001b[43mllama_cpp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllama_decode\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m    \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_code \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    314\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mllama_decode returned \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreturn_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/git/llm_test/.venv/lib/python3.10/site-packages/llama_cpp/llama_cpp.py:1622\u001b[0m, in \u001b[0;36mllama_decode\u001b[0;34m(ctx, batch)\u001b[0m\n\u001b[1;32m   1617\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mllama_decode\u001b[39m(ctx: llama_context_p, batch: llama_batch) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mint\u001b[39m:\n\u001b[1;32m   1618\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Positive return values does not mean a fatal error, but rather a warning.\u001b[39;00m\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;124;03m    0 - success\u001b[39;00m\n\u001b[1;32m   1620\u001b[0m \u001b[38;5;124;03m    1 - could not find a KV slot for the batch (try reducing the size of the batch or increase the context)\u001b[39;00m\n\u001b[1;32m   1621\u001b[0m \u001b[38;5;124;03m    < 0 - error\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1622\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_lib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllama_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "valid_question_answer = False  \n",
    "#Create a dataframe with the size of NUM_OF_SHUFFLES which contains the dataframe llm_exam_result\n",
    "shuffled_evalutation_df = pd.DataFrame(columns=[ 'Number of Questions','Correctly Answered','Incorrectly Answered','Accuracy','Accuracy Partial'])\n",
    "questions  = pd.read_parquet(QUESTIONS_BANK)\n",
    "\n",
    "#Take the first 20 questions\n",
    "#questions = questions.head(20)\n",
    "\n",
    "#questions = extract_answer_from_text_file(\"../data/questionbank_cisco_CCNP.txt\")\n",
    "callback_manager = CallbackManager([StreamingStdOutCallbackHandler()])\n",
    "prompt_template = PromptTemplate.from_template(PROMPT_TEMPLATE)\n",
    "\n",
    "#Iterate over each model definied in the MODEL_PATH dictionary\n",
    "for model, model_path in MODEL_PATH.items():\n",
    "     #Load the model wiht LLamaCpp\n",
    "    llm = LlamaCpp(\n",
    "        model_path= model_path,\n",
    "        n_gpu_layers=128,\n",
    "        n_batch=1024,\n",
    "        n_ctx=1100,\n",
    "        temperature=TEMPERATURE,\n",
    "        #top_p=0.9,\n",
    "        max_tokens = MAX_OUTPUT_TOKENS,\n",
    "        #callback_manager=callback_manager,\n",
    "        verbose=False,  # Verbose is required to pass to the callback manager\n",
    "    )\n",
    "\n",
    "    chain = prompt_template | llm\n",
    "    for shuffled_iteration in range(NUM_OF_SHUFFLES):\n",
    "        llm_exam_result = pd.DataFrame(columns = [\"Model\", \"QuestionIndex\", \"SamplingIndex\", \"NumberOfCorrectLLMAnswers\", \"NumberOfCorrectExamAnswers\", \"Ratio\", \"LLM_Answer\", \"Exam_Answers\", \"Answered_Correctly\",  \"Too_Many_answers\"]) \n",
    "        #Iterate over each question in the question dataframe\n",
    "        for index_question, row in questions.iterrows():\n",
    "            question = row['question']\n",
    "            choices = row['choices']\n",
    "            answers = row['answer']\n",
    "            num_of_correct_answer = len(answers)\n",
    "\n",
    "            choices = format_choices_for_llm(choices)\n",
    "\n",
    "            #Only if shuffle is enabled, shuffle the choices\n",
    "            if shuffled_iteration > 0:\n",
    "                choices, answers = shuffle_choices_and_update_answer(row['choices'], row['answer'])\n",
    "                num_of_correct_answer = len(answers)\n",
    "                choices = format_choices_for_llm(choices)\n",
    "            #Empty the char_probabilities dictionary for each question\n",
    "            char_probabilities = {}\n",
    "\n",
    "            #Iterate over the maximum sampling rate\n",
    "            for index_sampling in range(MAX_SAMPLING_RATE):\n",
    "                # Invoke the chain with the question and choices              \n",
    "                \n",
    "\n",
    "                llm_answer = chain.invoke({\"Exam_Question\" : row['question'], \"Exam_Choices\" : choices})            \n",
    "                # Check if the answer is in the expected format\n",
    "                if extract_answer(llm_answer) is not None:\n",
    "                    # Extract the correct answers from the LLM answer and analyse the answer\n",
    "                    num_of_correct_llm_answer, answerLLm, too_many_answers, answered_correctly = evaluation_sampling(llm_answer, answers, num_of_correct_answer)\n",
    "                    #Save the current sampling index -- How of the question has been asked until the answer was in the correct format\n",
    "                    sample_Index = index_sampling\n",
    "                    valid_question_answer = True\n",
    "                    break\n",
    "            \n",
    "            #Depending on the result of the answer, add the result to the dataframe\n",
    "            if not valid_question_answer:\n",
    "                new_row = pd.DataFrame({\"Model\": [model], \"QuestionIndex\": [index_question], \"SamplingIndex\": [-1], \"NumberOfCorrectLLMAnswers\": [0], \"NumberOfCorrectExamAnswers\": [num_of_correct_answer], \"Ratio\": [-1], \"LLM_Answer\": [llm_answer], \"Exam_Answers\": [answers]})\n",
    "                llm_exam_result = pd.concat([llm_exam_result, new_row], ignore_index=True)\n",
    "            else:\n",
    "                new_row = pd.DataFrame({\"Model\": [model], \"QuestionIndex\": [index_question], \"SamplingIndex\": [sample_Index], \"NumberOfCorrectLLMAnswers\": [num_of_correct_llm_answer], \"NumberOfCorrectExamAnswers\": [num_of_correct_answer], \"Ratio\": [num_of_correct_llm_answer/num_of_correct_answer], \"LLM_Answer\": [answerLLm], \"Exam_Answers\": [answers], \"Answered_Correctly\" : [answered_correctly], \"Too_Many_answers\": [too_many_answers]})\n",
    "                llm_exam_result = pd.concat([llm_exam_result, new_row], ignore_index=True)\n",
    "                valid_question_answer = False\n",
    "        answered_correctly = False\n",
    "        #Concat the the dataframe returned by evaulation to one dataframe\n",
    "        display(llm_exam_result)\n",
    "        #llm_exam_result.to_pickle(f\"../data/{model}_shuffled_{shuffled_iteration}_mmlu.pkl\")\n",
    "        evaluation_df = evaluation(llm_exam_result)\n",
    "        #Concat the evaluation dataframe to the complete dataframe\n",
    "        shuffled_evalutation_df = pd.concat([shuffled_evalutation_df, evaluation_df], ignore_index=True)\n",
    "        display(shuffled_evalutation_df)\n",
    "\n",
    "#plot_evaluation(shuffled_evalutation_df)\n",
    "model_statistics = calculate_model_statistics(shuffled_evalutation_df)\n",
    "display(model_statistics)\n",
    "plot_evaluation(model_statistics)\n",
    "#shuffled_evalutation_df.to_pickle(OUTPUT_EVALUATION_DETAILED)\n",
    "#model_statistics.to_pickle(OUTPUT_EVALUATION)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model, model_path in MODEL_PATH.items():\n",
    "    print(f\"Model: {model}\")\n",
    "    for shuffled_iteration in range(NUM_OF_SHUFFLES):\n",
    "        llm_exam_result = pd.read_pickle(f\"../data/{model}_shuffled_{shuffled_iteration}_201_301.pkl\")\n",
    "        evaluation_df = evaluation(llm_exam_result)\n",
    "        #Concat the evaluation dataframe to the complete dataframe\n",
    "        shuffled_evalutation_df = pd.concat([shuffled_evalutation_df, evaluation_df], ignore_index=True)\n",
    "model_statistics = calculate_model_statistics(shuffled_evalutation_df)\n",
    "display(model_statistics)\n",
    "plot_evaluation(model_statistics)\n",
    "shuffled_evalutation_df.to_pickle(OUTPUT_EVALUATION_DETAILED)\n",
    "model_statistics.to_pickle(OUTPUT_EVALUATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
