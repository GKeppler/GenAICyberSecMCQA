{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes\n",
    "\n",
    "### Dataset MMLU Computer Security:\n",
    "* https://huggingface.co/datasets/cais/mmlu/viewer/computer_security/test\n",
    "\n",
    "### Big Mistake in Prompt:\n",
    "**Added the \"\"\" after a linebreak e.g.** <br>\n",
    "Anwser: <br>\n",
    "\"\"\"<br>\n",
    "**Correct way:<br>**\n",
    "Anwser:\"\"\"\n",
    "\n",
    "## Cisco Pass exam\n",
    "* https://learningnetwork.cisco.com/s/question/0D53i00000U2TO7CAN/what-is-the-pass-percentage-required-to-get-in-ccna-200301\n",
    "* 825 / 1000 (82 %)\n",
    "\n",
    "## HELM  implementation: \n",
    "* Max_output tokens to restrict the possible outputs to the max number of answers possibilities\n",
    "* Temperature = 0\n",
    "* Joint strategy (all answer choices are presented at once)\n",
    "* Short Introduction: The following are multiple choice questions (with answers) about computer security.\n",
    "* (Paper: https://arxiv.org/pdf/2211.09110.pdf)\n",
    "\n",
    "## HELM / Paper Imprreovements:\n",
    "* Sampling --> std, mean min / max accuracy\n",
    "\n",
    "# CCNA 201-301 - 5 Shot like HELM with Answer format: Answer: ABC or Answer: A <br>\n",
    "### Oberservations Phi:\n",
    "* Output of Phi-Model always empty, similiar config as mmlu (temp=0, max_output_token = 2), by increasing temp the result of Phi is better but still not close to the other models<br>\n",
    "* Also have to increase the Max Output Tokens otherwise only \\n as response\n",
    "* Possible approach: Increasing temp and output_tokens, regex pattern that searchs for string in responses\n",
    "### Oberservations Llama 2:\n",
    "* LLama 2 results are much worse in comp. to single shot with Correct Answer: ['A', 'B'] and temp =0.7 and no limit to output tokens\n",
    "\n",
    "\n",
    "## New \n",
    "\n",
    "* ~~Yi, Llama 1, Llama 2 (nicht uncensored), Mixtral, Phi-2 --> Für MMLU~~\n",
    "* Change Answer to Letter (Frage: Exam Answer sind in HELM so, doch ändern?)\n",
    "* ~~Prompt without whitespace --> extra ~~\n",
    "* Ungeshuffeld vs HELM Grafik --> HELM vs unsere\n",
    "* Shuffle (min-max) vs nicht shuffeln\n",
    "* Dokumentieren --> Prompt, Changes Correct Answer Helm implementierung\n",
    "* Folien für Präsentation --> Implementierung, Ergebnisse (MMLU ähnlich wie HELM) --> , mit mehr Tokens CCNA Paper (Questionsbank nicht veröffentlicht) --> Weg Cisco (350-701 SCOR), Vetgleich zum Paper\n",
    "* Alles Dokumentieren\n",
    "* **How many points to pass? --> Horizontale** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from templates import *\n",
    "\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain_community.llms import LlamaCpp\n",
    "from langchain.callbacks.manager import CallbackManager\n",
    "import pandas as pd\n",
    "from langchain import PromptTemplate\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "import random\n",
    "import warnings\n",
    "import numpy as np\n",
    "import json\n",
    "warnings.filterwarnings('ignore')\n",
    "#Set the output limit to inf\n",
    "#pd.set_option('display.max_columns', None)\n",
    "#pd.set_option('display.max_rows', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = { \"Mixtral-8x-7b\": \"../models/mixtral-8x7b-instruct-v0.1.Q4_K_M.gguf\",\n",
    "               \"Phi-2\": \"../models/phi-2.Q5_K_M.gguf\",\n",
    "               \"Llama2-70b\": \"../models/llama-2-70b.Q5_K_M.gguf\",\n",
    "               \"Yi-34b\": \"../models/yi-34b-200k.Q5_K_M.gguf\",\n",
    "               \"Llama-65b\": \"../models/llama-65b.Q5_K_M.gguf\",\n",
    "              }\n",
    "\n",
    "########### Set the model parameters here ############\n",
    "\n",
    "#Parameter for changing the temperature of the model\n",
    "TEMPERATURE = 0\n",
    "\n",
    "#Parameter for max output tokens (for MMLU choose 1, since only Single choice)\n",
    "\n",
    "MAX_OUTPUT_TOKENS = 1\n",
    "\n",
    "########### Set the model parameters here ############\n",
    "\n",
    "\n",
    "#Sampling rate determines how often a question is asked again if the answer format is wrong\n",
    "MAX_SAMPLING_RATE = 5\n",
    "\n",
    "#Set to 1 if you dont want to shuffle\n",
    "NUM_OF_SHUFFLES = 1\n",
    "\n",
    "\n",
    "########### Set the names for result / evaluation files here ############\n",
    "\n",
    "#Set run name\n",
    "RUN_NAME = \"5_Shot_201_301_CCNA\"\n",
    "\n",
    "#Set output file name\n",
    "OUTPUT_EVALUATION = \"../results/5_Shot_201_301_CCNA/llm_5_Shot_201_301.pkl\"\n",
    "\n",
    "#Filename output evaluation detailed\n",
    "OUTPUT_EVALUATION_DETAILED = \"../results/5_Shot_201_301_CCNA/llm_prob_result_detailed_201_301_CCNA_5_Shot.pkl\"\n",
    "\n",
    "#Set filename of json file\n",
    "OUTPUT_EVALUATION_JSON = \"../results/5_Shot_201_301_CCNA/llm_prob_result_201_301_CCNA_5_Shot.json\"\n",
    "\n",
    "########### Set the names for result files here ############\n",
    "\n",
    "\n",
    "########### Set the questionsbank here ############\n",
    "#Set the questionsbank\n",
    "QUESTIONS_BANK = \"../data/201-301-CCNA.parquet\" ##CCNA\n",
    "#QUESTIONS_BANK = \"../data/mmlu_Computer_Security.parquet\" ##CCNA\n",
    "########### Set the questionsbank here ############\n",
    "\n",
    "########### Set the prompt template here ############\n",
    "PROMPT_TEMPLATE = FEW_SHOT_TEMPLATE_MMLU\n",
    "########### Set the prompt template here ############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Save the parameters as a JSON file\n",
    "# parameters = {\n",
    "#     \"RUN_NAME\": RUN_NAME,  # Ersetzen Sie durch den tatsächlichen Wert\n",
    "#     \"QUESTION_BANK\": QUESTIONS_BANK,  # Ersetzen Sie durch den tatsächlichen Wert\n",
    "#     \"MAX_SAMPLING_RATE\": MAX_SAMPLING_RATE,  # Ersetzen Sie durch den tatsächlichen Wert\n",
    "#     \"NUM_OF_SHUFFLES\": NUM_OF_SHUFFLES,  # Ersetzen Sie durch den tatsächlichen Wert\n",
    "#     \"FEW_SHOT_TEMPLATE\": PROMPT_TEMPLATE,  # Ersetzen Sie durch den tatsächlichen Wert\n",
    "#     \"TEMPERATURE\": TEMPERATURE,  # Ersetzen Sie durch den tatsächlichen Wert\n",
    "#     \"MAX_TOKENS\": MAX_OUTPUT_TOKENS  # Ersetzen Sie durch den tatsächlichen Wert\n",
    "# }\n",
    "\n",
    "# # Speichern Sie das Wörterbuch als JSON-Datei\n",
    "# with open(OUTPUT_EVALUATION_JSON, 'w') as f:\n",
    "#     json.dump(parameters, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_answer(answer):\n",
    "    \"\"\"Extracts the correct answers from the provided answer string.\n",
    "\n",
    "    Args:\n",
    "        answer: The answer string to extract the correct answers from.\n",
    "\n",
    "    Returns:\n",
    "        A list of correct answers (e.g., ['A', 'B']) if found, otherwise None. \n",
    "    \"\"\"\n",
    "    #print(repr(answer))\n",
    "    answer = re.sub(r'[\\s\\n.,]', '', answer)\n",
    "    pattern = re.compile(r'^[A-Z,]*$')\n",
    "    #print(answer)\n",
    "    if re.match(pattern, answer):\n",
    "        if ',' in answer:\n",
    "            return None\n",
    "        else:\n",
    "            return list(answer)\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def compare_answers(answerLLM, answer_exam):\n",
    "    \"\"\"Compares the extracted correct answers with the answers in answer_exam.\n",
    "\n",
    "    Keyword arguments:\n",
    "    answerLLM -- the list of answers extracted from the LLM answer\n",
    "    answer_exam -- list of answers from the exam\n",
    "    \"\"\"\n",
    "    # Convert answer_exam_list from letters to numbers\n",
    "    answerLLM = [ord(answer) - 65 for answer in answerLLM]\n",
    "\n",
    "    # Get number of correct answers in the exam\n",
    "    num_of_correct_exam_answers = len(answer_exam)\n",
    "\n",
    "    # Convert both lists to sets for efficient comparison\n",
    "    answer_LLM_set = set(answerLLM)\n",
    "    answer_exam_set = set(answer_exam)\n",
    "\n",
    "    # Calculate the count of matching answers\n",
    "    number_of_correct_llm_answers = len(answer_LLM_set.intersection(answer_exam_set))\n",
    "\n",
    "    # Check if the number of answers given by the LLM is greater than the number of correct answers\n",
    "    too_many_answ_given = False\n",
    "    if len(answer_LLM_set) > num_of_correct_exam_answers:\n",
    "        too_many_answ_given = True\n",
    "\n",
    "    # Return a dictionary with the matching count and the number of correct answers\n",
    "    return number_of_correct_llm_answers, too_many_answ_given\n",
    "\n",
    "def format_choices_for_llm(choices):\n",
    "    #Define the letters for the choices\n",
    "    letters = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J']\n",
    "    \n",
    "    # Erstellen Sie den formatierten String\n",
    "    formatted_choices = '\\n'.join(f'{letters[i]}. {choice}' for i, choice in enumerate(choices))\n",
    "    \n",
    "    return formatted_choices\n",
    "\n",
    "def evaluation_sampling(llm_answer, exam_Answers, num_of_correct_answer):\n",
    "    \"\"\"Analyse the answer given by the LLM and compare it with the exam answers.\n",
    "\n",
    "    Keyword arguments:\n",
    "    llm_answer -- the answer string given by the LLM\n",
    "    exam_Answers -- the list of answers from the exam\n",
    "    \"\"\"\n",
    "\n",
    "    answerLLM = extract_answer(llm_answer)\n",
    "    if answerLLM is not None:\n",
    "        num_of_correct_llm_Answers, too_many_answ = compare_answers(answerLLM, exam_Answers)\n",
    "        if num_of_correct_llm_Answers == num_of_correct_answer and too_many_answ == False:\n",
    "            answered_correctly = True\n",
    "        else:\n",
    "            answered_correctly = False \n",
    "        return num_of_correct_llm_Answers, answerLLM, too_many_answ, answered_correctly\n",
    "    else:\n",
    "         return -1\n",
    "\n",
    "\n",
    "def evaluation(llm_output_dataframe):\n",
    "\n",
    "    # Compute the number of total questions for each model\n",
    "    number_of_questions = llm_output_dataframe.groupby('Model')['QuestionIndex'].count()\n",
    "    \n",
    "    #Number of fully correct answers given by the LLM\n",
    "    correctly_answered = llm_output_dataframe.groupby('Model')['Answered_Correctly'].sum()\n",
    "\n",
    "    #Number of incorrect answers given by the LLM\n",
    "    incorrectly_answered = number_of_questions - correctly_answered\n",
    "\n",
    "    #Amount of correct answers in the exam\n",
    "    amount_correcct_exam_answers = llm_output_dataframe.groupby('Model')['NumberOfCorrectExamAnswers'].sum()\n",
    "\n",
    "    #Amount of correct answers given by the LLM even if not fully correct\n",
    "    amount_correcct_llm_answers = llm_output_dataframe.groupby('Model')['NumberOfCorrectLLMAnswers'].sum()\n",
    "    \n",
    "    #Calculation of Accuracy and Recall and f1 score\n",
    "    accuracy = correctly_answered / number_of_questions\n",
    "    accuracy_partial = amount_correcct_llm_answers / amount_correcct_exam_answers\n",
    "\n",
    "\n",
    "    results_df = pd.DataFrame({\n",
    "        'Number of Questions': number_of_questions,\n",
    "        'Correctly Answered': correctly_answered,\n",
    "        'Incorrectly Answered': incorrectly_answered,\n",
    "        'Accuracy': accuracy,\n",
    "        'Accuracy Partial': accuracy_partial,\n",
    "    })\n",
    "\n",
    "    results_df = results_df.reset_index()\n",
    "\n",
    "    return results_df\n",
    "\n",
    "\n",
    "def plot_evaluation(evaluation_df):\n",
    "    \"\"\"\n",
    "    Plots evaluation metrics from a DataFrame containing columns:\n",
    "        - 'Model'\n",
    "        - 'Accuracy Mean', 'Accuracy Min', 'Accuracy Max'\n",
    "        - 'Accuracy Partial Mean', 'Accuracy Partial Min', 'Accuracy Partial Max'\n",
    "    \"\"\"\n",
    "\n",
    "    # Define a list of colors for the models\n",
    "    colors = ['b', 'g', 'r', 'c', 'm', 'y', 'k']\n",
    "\n",
    "    # Define bar width\n",
    "    bar_width = 0.5  # Increase bar width for thicker bars\n",
    "\n",
    "    # --- Subplot 1: Accuracy ---\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "    for i, model in enumerate(evaluation_df['Model']):\n",
    "        bars = axs[0].bar(i + bar_width * i, evaluation_df.loc[i, 'Accuracy Mean'], bar_width, \n",
    "                   yerr=[[abs(evaluation_df.loc[i, 'Accuracy Mean'] - evaluation_df.loc[i, 'Accuracy Min'])], [abs(evaluation_df.loc[i, 'Accuracy Max'] - evaluation_df.loc[i, 'Accuracy Mean'])]],\n",
    "                   label=model, color=colors[i % len(colors)], capsize=5)\n",
    "\n",
    "    axs[0].set_ylabel('Accuracy (%)')\n",
    "    axs[0].set_title('Accuracy Mean with Error Bars (Max and Min)', fontsize=12)\n",
    "    axs[0].set_xticks([i + bar_width * i for i in range(len(evaluation_df['Model']))])\n",
    "    axs[0].set_xticklabels(evaluation_df['Model'], rotation=45, ha='right', fontsize=10)\n",
    "    axs[0].legend()\n",
    "    axs[0].set_ylim([0, 1])\n",
    "    axs[0].yaxis.set_major_locator(mtick.MultipleLocator(0.1))\n",
    "    axs[0].yaxis.set_major_formatter(mtick.PercentFormatter(1.0))\n",
    "    axs[0].grid(True, linestyle='dotted', axis='y')\n",
    "\n",
    "    # --- Subplot 2: Partial Accuracy ---\n",
    "    for i, model in enumerate(evaluation_df['Model']):\n",
    "        bars = axs[1].bar(i + bar_width * i, evaluation_df.loc[i, 'Accuracy Partial Mean'], bar_width,\n",
    "                   yerr=[[abs(evaluation_df.loc[i, 'Accuracy Partial Mean'] - evaluation_df.loc[i, 'Accuracy Partial Min'])], [abs(evaluation_df.loc[i, 'Accuracy Partial Max'] - evaluation_df.loc[i, 'Accuracy Partial Mean'])]],\n",
    "                   label=model, color=colors[i % len(colors)], capsize=5)\n",
    "\n",
    "    axs[1].set_ylabel('Accuracy Partial (%)')\n",
    "    axs[1].set_title('Accuracy Partial Mean with Error Bars (Max and Min)', fontsize=12)\n",
    "    axs[1].set_xticks([i + bar_width * i for i in range(len(evaluation_df['Model']))])\n",
    "    axs[1].set_xticklabels(evaluation_df['Model'], rotation=45, ha='right', fontsize=10)\n",
    "    axs[1].legend()\n",
    "    axs[1].set_ylim([0, 1])\n",
    "    axs[1].yaxis.set_major_locator(mtick.MultipleLocator(0.1))\n",
    "    axs[1].yaxis.set_major_formatter(mtick.PercentFormatter(1.0))\n",
    "    axs[1].grid(True, linestyle='dotted', axis='y')\n",
    "\n",
    "    fig.tight_layout(pad=1.2)  # Decrease padding for closer plots\n",
    "    plt.show()\n",
    "\n",
    "def calculate_model_statistics(df):\n",
    "    \"\"\"\n",
    "    Calculates statistics for each model in the DataFrame.\n",
    "    \n",
    "    Args:\n",
    "    df (DataFrame): Input DataFrame containing evaluation metrics for different models.\n",
    "    \n",
    "    Returns:\n",
    "    DataFrame: New DataFrame containing calculated statistics for each model.\n",
    "    \"\"\"\n",
    "    model_stats = []\n",
    "    for model, group_df in df.groupby('Model'):\n",
    "        model_stat = {\n",
    "            'Model': model,\n",
    "            'Accuracy Mean': group_df['Accuracy'].mean(),\n",
    "            'Accuracy Max': group_df['Accuracy'].max(),\n",
    "            'Accuracy Min': group_df['Accuracy'].min(),\n",
    "            'Accuracy STD': group_df['Accuracy'].std(),\n",
    "            'Accuracy Partial Mean': group_df['Accuracy Partial'].mean(),\n",
    "            'Accuracy Partial Max': group_df['Accuracy Partial'].max(),\n",
    "            'Accuracy Partial Min': group_df['Accuracy Partial'].min(),\n",
    "            'Accuracy Partial STD': group_df['Accuracy Partial'].std()\n",
    "        }\n",
    "        model_stats.append(model_stat)\n",
    "    \n",
    "    return pd.DataFrame(model_stats)\n",
    "\n",
    "\n",
    "def shuffle_choices_and_update_answer(choices, answer):\n",
    "    # Erstellen Sie eine Liste von Indizes und mischen Sie sie\n",
    "    indices = list(range(len(choices)))\n",
    "    random.shuffle(indices)\n",
    "    \n",
    "    # Verwenden Sie die gemischten Indizes, um die Auswahlmöglichkeiten und die Antwort zu aktualisieren\n",
    "    shuffled_choices = [choices[i] for i in indices]\n",
    "    updated_answer = [indices.index(a) for a in answer]  # Entfernen Sie +1, um 0-basierte Indizes zu verwenden\n",
    "    \n",
    "    return shuffled_choices, updated_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_question_answer = False  \n",
    "#Create a dataframe with the size of NUM_OF_SHUFFLES which contains the dataframe llm_exam_result\n",
    "shuffled_evalutation_df = pd.DataFrame(columns=[ 'Number of Questions','Correctly Answered','Incorrectly Answered','Accuracy','Accuracy Partial'])\n",
    "questions  = pd.read_parquet(QUESTIONS_BANK)\n",
    "\n",
    "#Take the first 20 questions\n",
    "#questions = questions.head(20)\n",
    "\n",
    "#questions = extract_answer_from_text_file(\"../data/questionbank_cisco_CCNP.txt\")\n",
    "callback_manager = CallbackManager([StreamingStdOutCallbackHandler()])\n",
    "prompt_template = PromptTemplate.from_template(PROMPT_TEMPLATE)\n",
    "\n",
    "#Iterate over each model definied in the MODEL_PATH dictionary\n",
    "for model, model_path in MODEL_PATH.items():\n",
    "     #Load the model wiht LLamaCpp\n",
    "    llm = LlamaCpp(\n",
    "        model_path= model_path,\n",
    "        n_gpu_layers=128,\n",
    "        n_batch=1024,\n",
    "        n_ctx=1100,\n",
    "        temperature=TEMPERATURE,\n",
    "        top_p=1,\n",
    "        max_tokens = MAX_OUTPUT_TOKENS,\n",
    "        #callback_manager=callback_manager,\n",
    "        verbose=False,  # Verbose is required to pass to the callback manager\n",
    "    )\n",
    "\n",
    "    chain = prompt_template | llm\n",
    "    for shuffled_iteration in range(NUM_OF_SHUFFLES):\n",
    "        llm_exam_result = pd.DataFrame(columns = [\"Model\", \"QuestionIndex\", \"SamplingIndex\", \"NumberOfCorrectLLMAnswers\", \"NumberOfCorrectExamAnswers\", \"Ratio\", \"LLM_Answer\", \"Exam_Answers\", \"Answered_Correctly\",  \"Too_Many_answers\"]) \n",
    "        #Iterate over each question in the question dataframe\n",
    "        for index_question, row in questions.iterrows():\n",
    "            question = row['question']\n",
    "            choices = row['choices']\n",
    "            answers = row['answer']\n",
    "            num_of_correct_answer = len(answers)\n",
    "\n",
    "            choices = format_choices_for_llm(choices)\n",
    "\n",
    "            #Only if shuffle is enabled, shuffle the choices\n",
    "            if shuffled_iteration > 0:\n",
    "                choices, answers = shuffle_choices_and_update_answer(row['choices'], row['answer'])\n",
    "                num_of_correct_answer = len(answers)\n",
    "                choices = format_choices_for_llm(choices)\n",
    "            #Empty the char_probabilities dictionary for each question\n",
    "            char_probabilities = {}\n",
    "\n",
    "            #Iterate over the maximum sampling rate\n",
    "            for index_sampling in range(MAX_SAMPLING_RATE):\n",
    "                # Invoke the chain with the question and choices              \n",
    "                \n",
    "\n",
    "                ########### Print the question and choices ############\n",
    "                #print(f\"Question: {question}\")\n",
    "                #print(choices)\n",
    "\n",
    "                llm_answer = chain.invoke({\"Exam_Question\" : row['question'], \"Exam_Choices\" : choices})            \n",
    "                # Check if the answer is in the expected format\n",
    "                if extract_answer(llm_answer) is not None:\n",
    "                    # Extract the correct answers from the LLM answer and analyse the answer\n",
    "                    num_of_correct_llm_answer, answerLLm, too_many_answers, answered_correctly = evaluation_sampling(llm_answer, answers, num_of_correct_answer)\n",
    "                    #Save the current sampling index -- How of the question has been asked until the answer was in the correct format\n",
    "                    sample_Index = index_sampling\n",
    "                    valid_question_answer = True\n",
    "                    break\n",
    "            \n",
    "            #Depending on the result of the answer, add the result to the dataframe\n",
    "            if not valid_question_answer:\n",
    "                new_row = pd.DataFrame({\"Model\": [model], \"QuestionIndex\": [index_question], \"SamplingIndex\": [-1], \"NumberOfCorrectLLMAnswers\": [0], \"NumberOfCorrectExamAnswers\": [num_of_correct_answer], \"Ratio\": [-1], \"LLM_Answer\": [llm_answer], \"Exam_Answers\": [answers]})\n",
    "                llm_exam_result = pd.concat([llm_exam_result, new_row], ignore_index=True)\n",
    "            else:\n",
    "                new_row = pd.DataFrame({\"Model\": [model], \"QuestionIndex\": [index_question], \"SamplingIndex\": [sample_Index], \"NumberOfCorrectLLMAnswers\": [num_of_correct_llm_answer], \"NumberOfCorrectExamAnswers\": [num_of_correct_answer], \"Ratio\": [num_of_correct_llm_answer/num_of_correct_answer], \"LLM_Answer\": [answerLLm], \"Exam_Answers\": [answers], \"Answered_Correctly\" : [answered_correctly], \"Too_Many_answers\": [too_many_answers]})\n",
    "                llm_exam_result = pd.concat([llm_exam_result, new_row], ignore_index=True)\n",
    "                valid_question_answer = False\n",
    "        answered_correctly = False\n",
    "        #Concat the the dataframe returned by evaulation to one dataframe\n",
    "        display(llm_exam_result)\n",
    "        #llm_exam_result.to_pickle(f\"../data/{model}_shuffled_{shuffled_iteration}_mmlu.pkl\")\n",
    "        evaluation_df = evaluation(llm_exam_result)\n",
    "        #Concat the evaluation dataframe to the complete dataframe\n",
    "        shuffled_evalutation_df = pd.concat([shuffled_evalutation_df, evaluation_df], ignore_index=True)\n",
    "        display(shuffled_evalutation_df)\n",
    "\n",
    "#plot_evaluation(shuffled_evalutation_df)\n",
    "model_statistics = calculate_model_statistics(shuffled_evalutation_df)\n",
    "display(model_statistics)\n",
    "plot_evaluation(model_statistics)\n",
    "#shuffled_evalutation_df.to_pickle(OUTPUT_EVALUATION_DETAILED)\n",
    "#model_statistics.to_pickle(OUTPUT_EVALUATION)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changed Prompt, no whitespace between solution letter and answer --> Anwser: A /// now Answer:A\n",
    "* Whitespace-Problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_question_answer = False  \n",
    "#Create a dataframe with the size of NUM_OF_SHUFFLES which contains the dataframe llm_exam_result\n",
    "shuffled_evalutation_df = pd.DataFrame(columns=[ 'Number of Questions','Correctly Answered','Incorrectly Answered','Accuracy','Accuracy Partial'])\n",
    "questions  = pd.read_parquet(QUESTIONS_BANK)\n",
    "\n",
    "#Take the first 20 questions\n",
    "#questions = questions.head(20)\n",
    "\n",
    "#questions = extract_answer_from_text_file(\"../data/questionbank_cisco_CCNP.txt\")\n",
    "callback_manager = CallbackManager([StreamingStdOutCallbackHandler()])\n",
    "prompt_template = PromptTemplate.from_template(FEW_SHOT_TEMPLATE_MMLU_NO_WHITESPACE)\n",
    "\n",
    "#Iterate over each model definied in the MODEL_PATH dictionary\n",
    "for model, model_path in MODEL_PATH.items():\n",
    "     #Load the model wiht LLamaCpp\n",
    "    llm = LlamaCpp(\n",
    "        model_path= model_path,\n",
    "        n_gpu_layers=128,\n",
    "        n_batch=1024,\n",
    "        n_ctx=1100,\n",
    "        temperature=TEMPERATURE,\n",
    "        top_p=1,\n",
    "        max_tokens = MAX_OUTPUT_TOKENS,\n",
    "        #callback_manager=callback_manager,\n",
    "        verbose=False,  # Verbose is required to pass to the callback manager\n",
    "    )\n",
    "\n",
    "    chain = prompt_template | llm\n",
    "    for shuffled_iteration in range(NUM_OF_SHUFFLES):\n",
    "        llm_exam_result = pd.DataFrame(columns = [\"Model\", \"QuestionIndex\", \"SamplingIndex\", \"NumberOfCorrectLLMAnswers\", \"NumberOfCorrectExamAnswers\", \"Ratio\", \"LLM_Answer\", \"Exam_Answers\", \"Answered_Correctly\",  \"Too_Many_answers\"]) \n",
    "        #Iterate over each question in the question dataframe\n",
    "        for index_question, row in questions.iterrows():\n",
    "            question = row['question']\n",
    "            choices = row['choices']\n",
    "            answers = row['answer']\n",
    "            num_of_correct_answer = len(answers)\n",
    "\n",
    "            choices = format_choices_for_llm(choices)\n",
    "\n",
    "            #Only if shuffle is enabled, shuffle the choices\n",
    "            if shuffled_iteration > 0:\n",
    "                choices, answers = shuffle_choices_and_update_answer(row['choices'], row['answer'])\n",
    "                num_of_correct_answer = len(answers)\n",
    "                choices = format_choices_for_llm(choices)\n",
    "            #Empty the char_probabilities dictionary for each question\n",
    "            char_probabilities = {}\n",
    "\n",
    "            #Iterate over the maximum sampling rate\n",
    "            for index_sampling in range(MAX_SAMPLING_RATE):\n",
    "                # Invoke the chain with the question and choices              \n",
    "                \n",
    "                                \n",
    "                #print(f\"Question: {question}\")\n",
    "                #print(choices)\n",
    "\n",
    "                llm_answer = chain.invoke({\"Exam_Question\" : row['question'], \"Exam_Choices\" : choices})            \n",
    "                # Check if the answer is in the expected format\n",
    "                if extract_answer(llm_answer) is not None:\n",
    "                    # Extract the correct answers from the LLM answer and analyse the answer\n",
    "                    num_of_correct_llm_answer, answerLLm, too_many_answers, answered_correctly = evaluation_sampling(llm_answer, answers, num_of_correct_answer)\n",
    "                    #Save the current sampling index -- How of the question has been asked until the answer was in the correct format\n",
    "                    sample_Index = index_sampling\n",
    "                    valid_question_answer = True\n",
    "                    break\n",
    "            \n",
    "            #Depending on the result of the answer, add the result to the dataframe\n",
    "            if not valid_question_answer:\n",
    "                new_row = pd.DataFrame({\"Model\": [model], \"QuestionIndex\": [index_question], \"SamplingIndex\": [-1], \"NumberOfCorrectLLMAnswers\": [0], \"NumberOfCorrectExamAnswers\": [num_of_correct_answer], \"Ratio\": [-1], \"LLM_Answer\": [llm_answer], \"Exam_Answers\": [answers]})\n",
    "                llm_exam_result = pd.concat([llm_exam_result, new_row], ignore_index=True)\n",
    "            else:\n",
    "                new_row = pd.DataFrame({\"Model\": [model], \"QuestionIndex\": [index_question], \"SamplingIndex\": [sample_Index], \"NumberOfCorrectLLMAnswers\": [num_of_correct_llm_answer], \"NumberOfCorrectExamAnswers\": [num_of_correct_answer], \"Ratio\": [num_of_correct_llm_answer/num_of_correct_answer], \"LLM_Answer\": [answerLLm], \"Exam_Answers\": [answers], \"Answered_Correctly\" : [answered_correctly], \"Too_Many_answers\": [too_many_answers]})\n",
    "                llm_exam_result = pd.concat([llm_exam_result, new_row], ignore_index=True)\n",
    "                valid_question_answer = False\n",
    "        answered_correctly = False\n",
    "        #Concat the the dataframe returned by evaulation to one dataframe\n",
    "        display(llm_exam_result)\n",
    "        #llm_exam_result.to_pickle(f\"../data/{model}_shuffled_{shuffled_iteration}_mmlu.pkl\")\n",
    "        evaluation_df = evaluation(llm_exam_result)\n",
    "        #Concat the evaluation dataframe to the complete dataframe\n",
    "        shuffled_evalutation_df = pd.concat([shuffled_evalutation_df, evaluation_df], ignore_index=True)\n",
    "        display(shuffled_evalutation_df)\n",
    "\n",
    "#plot_evaluation(shuffled_evalutation_df)\n",
    "model_statistics = calculate_model_statistics(shuffled_evalutation_df)\n",
    "display(model_statistics)\n",
    "plot_evaluation(model_statistics)\n",
    "#shuffled_evalutation_df.to_pickle(OUTPUT_EVALUATION_DETAILED)\n",
    "#model_statistics.to_pickle(OUTPUT_EVALUATION)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ggml_init_cublas: GGML_CUDA_FORCE_MMQ:   no\n",
      "ggml_init_cublas: CUDA_USE_TENSOR_CORES: yes\n",
      "ggml_init_cublas: found 2 CUDA devices:\n",
      "  Device 0: NVIDIA A100-SXM4-40GB, compute capability 8.0, VMM: yes\n",
      "  Device 1: NVIDIA A100-SXM4-40GB, compute capability 8.0, VMM: yes\n",
      "llama_model_loader: loaded meta data with 26 key-value pairs and 995 tensors from ../models/mixtral-8x7b-instruct-v0.1.Q4_K_M.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.name str              = mistralai_mixtral-8x7b-instruct-v0.1\n",
      "llama_model_loader: - kv   2:                       llama.context_length u32              = 32768\n",
      "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n",
      "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 14336\n",
      "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv   9:                         llama.expert_count u32              = 8\n",
      "llama_model_loader: - kv  10:                    llama.expert_used_count u32              = 2\n",
      "llama_model_loader: - kv  11:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  12:                       llama.rope.freq_base f32              = 1000000.000000\n",
      "llama_model_loader: - kv  13:                          general.file_type u32              = 15\n",
      "llama_model_loader: - kv  14:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  15:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
      "llama_model_loader: - kv  16:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
      "llama_model_loader: - kv  17:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
      "llama_model_loader: - kv  18:                tokenizer.ggml.bos_token_id u32              = 1\n",
      "llama_model_loader: - kv  19:                tokenizer.ggml.eos_token_id u32              = 2\n",
      "llama_model_loader: - kv  20:            tokenizer.ggml.unknown_token_id u32              = 0\n",
      "llama_model_loader: - kv  21:            tokenizer.ggml.padding_token_id u32              = 0\n",
      "llama_model_loader: - kv  22:               tokenizer.ggml.add_bos_token bool             = true\n",
      "llama_model_loader: - kv  23:               tokenizer.ggml.add_eos_token bool             = false\n",
      "llama_model_loader: - kv  24:                    tokenizer.chat_template str              = {{ bos_token }}{% for message in mess...\n",
      "llama_model_loader: - kv  25:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   65 tensors\n",
      "llama_model_loader: - type  f16:   32 tensors\n",
      "llama_model_loader: - type q8_0:   64 tensors\n",
      "llama_model_loader: - type q4_K:  833 tensors\n",
      "llama_model_loader: - type q6_K:    1 tensors\n",
      "llm_load_vocab: special tokens definition check successful ( 259/32000 ).\n",
      "llm_load_print_meta: format           = GGUF V3 (latest)\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = SPM\n",
      "llm_load_print_meta: n_vocab          = 32000\n",
      "llm_load_print_meta: n_merges         = 0\n",
      "llm_load_print_meta: n_ctx_train      = 32768\n",
      "llm_load_print_meta: n_embd           = 4096\n",
      "llm_load_print_meta: n_head           = 32\n",
      "llm_load_print_meta: n_head_kv        = 8\n",
      "llm_load_print_meta: n_layer          = 32\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_embd_head_k    = 128\n",
      "llm_load_print_meta: n_embd_head_v    = 128\n",
      "llm_load_print_meta: n_gqa            = 4\n",
      "llm_load_print_meta: n_embd_k_gqa     = 1024\n",
      "llm_load_print_meta: n_embd_v_gqa     = 1024\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 14336\n",
      "llm_load_print_meta: n_expert         = 8\n",
      "llm_load_print_meta: n_expert_used    = 2\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 1000000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_yarn_orig_ctx  = 32768\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: model type       = 7B\n",
      "llm_load_print_meta: model ftype      = Q4_K - Medium\n",
      "llm_load_print_meta: model params     = 46.70 B\n",
      "llm_load_print_meta: model size       = 24.62 GiB (4.53 BPW) \n",
      "llm_load_print_meta: general.name     = mistralai_mixtral-8x7b-instruct-v0.1\n",
      "llm_load_print_meta: BOS token        = 1 '<s>'\n",
      "llm_load_print_meta: EOS token        = 2 '</s>'\n",
      "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
      "llm_load_print_meta: PAD token        = 0 '<unk>'\n",
      "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
      "llm_load_tensors: ggml ctx size =    1.14 MiB\n",
      "llm_load_tensors: offloading 32 repeating layers to GPU\n",
      "llm_load_tensors: offloading non-repeating layers to GPU\n",
      "llm_load_tensors: offloaded 33/33 layers to GPU\n",
      "llm_load_tensors:        CPU buffer size =    70.31 MiB\n",
      "llm_load_tensors:      CUDA0 buffer size = 13304.09 MiB\n",
      "llm_load_tensors:      CUDA1 buffer size = 11841.46 MiB\n",
      "....................................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 1100\n",
      "llama_new_context_with_model: freq_base  = 10000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "llama_kv_cache_init:      CUDA0 KV buffer size =    73.05 MiB\n",
      "llama_kv_cache_init:      CUDA1 KV buffer size =    64.45 MiB\n",
      "llama_new_context_with_model: KV self size  =  137.50 MiB, K (f16):   68.75 MiB, V (f16):   68.75 MiB\n",
      "llama_new_context_with_model:  CUDA_Host input buffer size   =    20.31 MiB\n",
      "llama_new_context_with_model:      CUDA0 compute buffer size =   270.45 MiB\n",
      "llama_new_context_with_model:      CUDA1 compute buffer size =   287.99 MiB\n",
      "llama_new_context_with_model:  CUDA_Host compute buffer size =    17.60 MiB\n",
      "llama_new_context_with_model: graph splits (measure): 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>QuestionIndex</th>\n",
       "      <th>SamplingIndex</th>\n",
       "      <th>NumberOfCorrectLLMAnswers</th>\n",
       "      <th>NumberOfCorrectExamAnswers</th>\n",
       "      <th>Ratio</th>\n",
       "      <th>LLM_Answer</th>\n",
       "      <th>Exam_Answers</th>\n",
       "      <th>Answered_Correctly</th>\n",
       "      <th>Too_Many_answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mixtral-8x-7b</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[A, D]</td>\n",
       "      <td>[0, 3]</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mixtral-8x-7b</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[A]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mixtral-8x-7b</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[A]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mixtral-8x-7b</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[A]</td>\n",
       "      <td>[2]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mixtral-8x-7b</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[C]</td>\n",
       "      <td>[2]</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>Mixtral-8x-7b</td>\n",
       "      <td>199</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[C]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>Mixtral-8x-7b</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[D]</td>\n",
       "      <td>[3]</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>Mixtral-8x-7b</td>\n",
       "      <td>201</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[A]</td>\n",
       "      <td>[3]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>Mixtral-8x-7b</td>\n",
       "      <td>202</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[C]</td>\n",
       "      <td>[2]</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>Mixtral-8x-7b</td>\n",
       "      <td>203</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[D]</td>\n",
       "      <td>[3]</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>204 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Model QuestionIndex SamplingIndex NumberOfCorrectLLMAnswers  \\\n",
       "0    Mixtral-8x-7b             0             0                         2   \n",
       "1    Mixtral-8x-7b             1             0                         1   \n",
       "2    Mixtral-8x-7b             2             0                         1   \n",
       "3    Mixtral-8x-7b             3             0                         0   \n",
       "4    Mixtral-8x-7b             4             0                         1   \n",
       "..             ...           ...           ...                       ...   \n",
       "199  Mixtral-8x-7b           199             0                         0   \n",
       "200  Mixtral-8x-7b           200             0                         1   \n",
       "201  Mixtral-8x-7b           201             0                         0   \n",
       "202  Mixtral-8x-7b           202             0                         1   \n",
       "203  Mixtral-8x-7b           203             0                         1   \n",
       "\n",
       "    NumberOfCorrectExamAnswers  Ratio LLM_Answer Exam_Answers  \\\n",
       "0                            2    1.0     [A, D]       [0, 3]   \n",
       "1                            1    1.0        [A]          [0]   \n",
       "2                            1    1.0        [A]          [0]   \n",
       "3                            1    0.0        [A]          [2]   \n",
       "4                            1    1.0        [C]          [2]   \n",
       "..                         ...    ...        ...          ...   \n",
       "199                          1    0.0        [C]          [0]   \n",
       "200                          1    1.0        [D]          [3]   \n",
       "201                          1    0.0        [A]          [3]   \n",
       "202                          1    1.0        [C]          [2]   \n",
       "203                          1    1.0        [D]          [3]   \n",
       "\n",
       "    Answered_Correctly Too_Many_answers  \n",
       "0                 True            False  \n",
       "1                 True            False  \n",
       "2                 True            False  \n",
       "3                False            False  \n",
       "4                 True            False  \n",
       "..                 ...              ...  \n",
       "199              False            False  \n",
       "200               True            False  \n",
       "201              False            False  \n",
       "202               True            False  \n",
       "203               True            False  \n",
       "\n",
       "[204 rows x 10 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of Questions</th>\n",
       "      <th>Correctly Answered</th>\n",
       "      <th>Incorrectly Answered</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Accuracy Partial</th>\n",
       "      <th>Model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>204</td>\n",
       "      <td>127</td>\n",
       "      <td>77</td>\n",
       "      <td>0.622549</td>\n",
       "      <td>0.682731</td>\n",
       "      <td>Mixtral-8x-7b</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Number of Questions Correctly Answered Incorrectly Answered  Accuracy  \\\n",
       "0                 204                127                   77  0.622549   \n",
       "\n",
       "  Accuracy Partial          Model  \n",
       "0         0.682731  Mixtral-8x-7b  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 20 key-value pairs and 325 tensors from ../models/phi-2.Q5_K_M.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = phi2\n",
      "llama_model_loader: - kv   1:                               general.name str              = Phi2\n",
      "llama_model_loader: - kv   2:                        phi2.context_length u32              = 2048\n",
      "llama_model_loader: - kv   3:                      phi2.embedding_length u32              = 2560\n",
      "llama_model_loader: - kv   4:                   phi2.feed_forward_length u32              = 10240\n",
      "llama_model_loader: - kv   5:                           phi2.block_count u32              = 32\n",
      "llama_model_loader: - kv   6:                  phi2.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv   7:               phi2.attention.head_count_kv u32              = 32\n",
      "llama_model_loader: - kv   8:          phi2.attention.layer_norm_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv   9:                  phi2.rope.dimension_count u32              = 32\n",
      "llama_model_loader: - kv  10:                          general.file_type u32              = 17\n",
      "llama_model_loader: - kv  11:               tokenizer.ggml.add_bos_token bool             = false\n",
      "llama_model_loader: - kv  12:                       tokenizer.ggml.model str              = gpt2\n",
      "llama_model_loader: - kv  13:                      tokenizer.ggml.tokens arr[str,51200]   = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
      "llama_model_loader: - kv  14:                  tokenizer.ggml.token_type arr[i32,51200]   = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
      "llama_model_loader: - kv  15:                      tokenizer.ggml.merges arr[str,50000]   = [\"Ġ t\", \"Ġ a\", \"h e\", \"i n\", \"r e\",...\n",
      "llama_model_loader: - kv  16:                tokenizer.ggml.bos_token_id u32              = 50256\n",
      "llama_model_loader: - kv  17:                tokenizer.ggml.eos_token_id u32              = 50256\n",
      "llama_model_loader: - kv  18:            tokenizer.ggml.unknown_token_id u32              = 50256\n",
      "llama_model_loader: - kv  19:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:  195 tensors\n",
      "llama_model_loader: - type q5_K:   81 tensors\n",
      "llama_model_loader: - type q6_K:   49 tensors\n",
      "llm_load_vocab: mismatch in special tokens definition ( 910/51200 vs 944/51200 ).\n",
      "llm_load_print_meta: format           = GGUF V3 (latest)\n",
      "llm_load_print_meta: arch             = phi2\n",
      "llm_load_print_meta: vocab type       = BPE\n",
      "llm_load_print_meta: n_vocab          = 51200\n",
      "llm_load_print_meta: n_merges         = 50000\n",
      "llm_load_print_meta: n_ctx_train      = 2048\n",
      "llm_load_print_meta: n_embd           = 2560\n",
      "llm_load_print_meta: n_head           = 32\n",
      "llm_load_print_meta: n_head_kv        = 32\n",
      "llm_load_print_meta: n_layer          = 32\n",
      "llm_load_print_meta: n_rot            = 32\n",
      "llm_load_print_meta: n_embd_head_k    = 80\n",
      "llm_load_print_meta: n_embd_head_v    = 80\n",
      "llm_load_print_meta: n_gqa            = 1\n",
      "llm_load_print_meta: n_embd_k_gqa     = 2560\n",
      "llm_load_print_meta: n_embd_v_gqa     = 2560\n",
      "llm_load_print_meta: f_norm_eps       = 1.0e-05\n",
      "llm_load_print_meta: f_norm_rms_eps   = 0.0e+00\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 10240\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 10000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_yarn_orig_ctx  = 2048\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: model type       = 3B\n",
      "llm_load_print_meta: model ftype      = Q5_K - Medium\n",
      "llm_load_print_meta: model params     = 2.78 B\n",
      "llm_load_print_meta: model size       = 1.93 GiB (5.96 BPW) \n",
      "llm_load_print_meta: general.name     = Phi2\n",
      "llm_load_print_meta: BOS token        = 50256 '<|endoftext|>'\n",
      "llm_load_print_meta: EOS token        = 50256 '<|endoftext|>'\n",
      "llm_load_print_meta: UNK token        = 50256 '<|endoftext|>'\n",
      "llm_load_print_meta: LF token         = 128 'Ä'\n",
      "llm_load_tensors: ggml ctx size =    0.37 MiB\n",
      "llm_load_tensors: offloading 32 repeating layers to GPU\n",
      "llm_load_tensors: offloading non-repeating layers to GPU\n",
      "llm_load_tensors: offloaded 33/33 layers to GPU\n",
      "llm_load_tensors:        CPU buffer size =    85.94 MiB\n",
      "llm_load_tensors:      CUDA0 buffer size =   953.93 MiB\n",
      "llm_load_tensors:      CUDA1 buffer size =   935.08 MiB\n",
      "...........................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 1100\n",
      "llama_new_context_with_model: freq_base  = 10000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "llama_kv_cache_init:      CUDA0 KV buffer size =   182.62 MiB\n",
      "llama_kv_cache_init:      CUDA1 KV buffer size =   161.13 MiB\n",
      "llama_new_context_with_model: KV self size  =  343.75 MiB, K (f16):  171.88 MiB, V (f16):  171.88 MiB\n",
      "llama_new_context_with_model:  CUDA_Host input buffer size   =    14.31 MiB\n",
      "llama_new_context_with_model:      CUDA0 compute buffer size =   221.98 MiB\n",
      "llama_new_context_with_model:      CUDA1 compute buffer size =   242.00 MiB\n",
      "llama_new_context_with_model:  CUDA_Host compute buffer size =    11.00 MiB\n",
      "llama_new_context_with_model: graph splits (measure): 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>QuestionIndex</th>\n",
       "      <th>SamplingIndex</th>\n",
       "      <th>NumberOfCorrectLLMAnswers</th>\n",
       "      <th>NumberOfCorrectExamAnswers</th>\n",
       "      <th>Ratio</th>\n",
       "      <th>LLM_Answer</th>\n",
       "      <th>Exam_Answers</th>\n",
       "      <th>Answered_Correctly</th>\n",
       "      <th>Too_Many_answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Phi-2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>[B, D, C]</td>\n",
       "      <td>[0, 3]</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Phi-2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[D]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Phi-2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[C]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Phi-2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[A]</td>\n",
       "      <td>[2]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Phi-2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[C]</td>\n",
       "      <td>[2]</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>Phi-2</td>\n",
       "      <td>199</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[C]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>Phi-2</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[A]</td>\n",
       "      <td>[3]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>Phi-2</td>\n",
       "      <td>201</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[C]</td>\n",
       "      <td>[3]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>Phi-2</td>\n",
       "      <td>202</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[C]</td>\n",
       "      <td>[2]</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>Phi-2</td>\n",
       "      <td>203</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[B]</td>\n",
       "      <td>[3]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>204 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Model QuestionIndex SamplingIndex NumberOfCorrectLLMAnswers  \\\n",
       "0    Phi-2             0             0                         1   \n",
       "1    Phi-2             1             0                         0   \n",
       "2    Phi-2             2             0                         0   \n",
       "3    Phi-2             3             0                         0   \n",
       "4    Phi-2             4             0                         1   \n",
       "..     ...           ...           ...                       ...   \n",
       "199  Phi-2           199             0                         0   \n",
       "200  Phi-2           200             0                         0   \n",
       "201  Phi-2           201             0                         0   \n",
       "202  Phi-2           202             0                         1   \n",
       "203  Phi-2           203             0                         0   \n",
       "\n",
       "    NumberOfCorrectExamAnswers  Ratio LLM_Answer Exam_Answers  \\\n",
       "0                            2    0.5  [B, D, C]       [0, 3]   \n",
       "1                            1    0.0        [D]          [0]   \n",
       "2                            1    0.0        [C]          [0]   \n",
       "3                            1    0.0        [A]          [2]   \n",
       "4                            1    1.0        [C]          [2]   \n",
       "..                         ...    ...        ...          ...   \n",
       "199                          1    0.0        [C]          [0]   \n",
       "200                          1    0.0        [A]          [3]   \n",
       "201                          1    0.0        [C]          [3]   \n",
       "202                          1    1.0        [C]          [2]   \n",
       "203                          1    0.0        [B]          [3]   \n",
       "\n",
       "    Answered_Correctly Too_Many_answers  \n",
       "0                False             True  \n",
       "1                False            False  \n",
       "2                False            False  \n",
       "3                False            False  \n",
       "4                 True            False  \n",
       "..                 ...              ...  \n",
       "199              False            False  \n",
       "200              False            False  \n",
       "201              False            False  \n",
       "202               True            False  \n",
       "203              False            False  \n",
       "\n",
       "[204 rows x 10 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of Questions</th>\n",
       "      <th>Correctly Answered</th>\n",
       "      <th>Incorrectly Answered</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Accuracy Partial</th>\n",
       "      <th>Model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>204</td>\n",
       "      <td>127</td>\n",
       "      <td>77</td>\n",
       "      <td>0.622549</td>\n",
       "      <td>0.682731</td>\n",
       "      <td>Mixtral-8x-7b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>204</td>\n",
       "      <td>76</td>\n",
       "      <td>128</td>\n",
       "      <td>0.372549</td>\n",
       "      <td>0.502008</td>\n",
       "      <td>Phi-2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Number of Questions Correctly Answered Incorrectly Answered  Accuracy  \\\n",
       "0                 204                127                   77  0.622549   \n",
       "1                 204                 76                  128  0.372549   \n",
       "\n",
       "  Accuracy Partial          Model  \n",
       "0         0.682731  Mixtral-8x-7b  \n",
       "1         0.502008          Phi-2  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 19 key-value pairs and 723 tensors from ../models/llama-2-70b.Q5_K_M.gguf (version GGUF V2)\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.name str              = LLaMA v2\n",
      "llama_model_loader: - kv   2:                       llama.context_length u32              = 4096\n",
      "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 8192\n",
      "llama_model_loader: - kv   4:                          llama.block_count u32              = 80\n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 28672\n",
      "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 64\n",
      "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  10:                          general.file_type u32              = 17\n",
      "llama_model_loader: - kv  11:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  12:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
      "llama_model_loader: - kv  13:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
      "llama_model_loader: - kv  14:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
      "llama_model_loader: - kv  15:                tokenizer.ggml.bos_token_id u32              = 1\n",
      "llama_model_loader: - kv  16:                tokenizer.ggml.eos_token_id u32              = 2\n",
      "llama_model_loader: - kv  17:            tokenizer.ggml.unknown_token_id u32              = 0\n",
      "llama_model_loader: - kv  18:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:  161 tensors\n",
      "llama_model_loader: - type q5_K:  481 tensors\n",
      "llama_model_loader: - type q6_K:   81 tensors\n",
      "llm_load_vocab: special tokens definition check successful ( 259/32000 ).\n",
      "llm_load_print_meta: format           = GGUF V2\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = SPM\n",
      "llm_load_print_meta: n_vocab          = 32000\n",
      "llm_load_print_meta: n_merges         = 0\n",
      "llm_load_print_meta: n_ctx_train      = 4096\n",
      "llm_load_print_meta: n_embd           = 8192\n",
      "llm_load_print_meta: n_head           = 64\n",
      "llm_load_print_meta: n_head_kv        = 8\n",
      "llm_load_print_meta: n_layer          = 80\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_embd_head_k    = 128\n",
      "llm_load_print_meta: n_embd_head_v    = 128\n",
      "llm_load_print_meta: n_gqa            = 8\n",
      "llm_load_print_meta: n_embd_k_gqa     = 1024\n",
      "llm_load_print_meta: n_embd_v_gqa     = 1024\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 28672\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 10000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_yarn_orig_ctx  = 4096\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: model type       = 70B\n",
      "llm_load_print_meta: model ftype      = Q5_K - Medium\n",
      "llm_load_print_meta: model params     = 68.98 B\n",
      "llm_load_print_meta: model size       = 45.40 GiB (5.65 BPW) \n",
      "llm_load_print_meta: general.name     = LLaMA v2\n",
      "llm_load_print_meta: BOS token        = 1 '<s>'\n",
      "llm_load_print_meta: EOS token        = 2 '</s>'\n",
      "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
      "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
      "llm_load_tensors: ggml ctx size =    0.83 MiB\n",
      "llm_load_tensors: offloading 80 repeating layers to GPU\n",
      "llm_load_tensors: offloading non-repeating layers to GPU\n",
      "llm_load_tensors: offloaded 81/81 layers to GPU\n",
      "llm_load_tensors:        CPU buffer size =   171.88 MiB\n",
      "llm_load_tensors:      CUDA0 buffer size = 23619.81 MiB\n",
      "llm_load_tensors:      CUDA1 buffer size = 22702.80 MiB\n",
      "....................................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 1100\n",
      "llama_new_context_with_model: freq_base  = 10000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "llama_kv_cache_init:      CUDA0 KV buffer size =   176.17 MiB\n",
      "llama_kv_cache_init:      CUDA1 KV buffer size =   167.58 MiB\n",
      "llama_new_context_with_model: KV self size  =  343.75 MiB, K (f16):  171.88 MiB, V (f16):  171.88 MiB\n",
      "llama_new_context_with_model:  CUDA_Host input buffer size   =    36.31 MiB\n",
      "llama_new_context_with_model:      CUDA0 compute buffer size =   412.83 MiB\n",
      "llama_new_context_with_model:      CUDA1 compute buffer size =   412.83 MiB\n",
      "llama_new_context_with_model:  CUDA_Host compute buffer size =    35.20 MiB\n",
      "llama_new_context_with_model: graph splits (measure): 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>QuestionIndex</th>\n",
       "      <th>SamplingIndex</th>\n",
       "      <th>NumberOfCorrectLLMAnswers</th>\n",
       "      <th>NumberOfCorrectExamAnswers</th>\n",
       "      <th>Ratio</th>\n",
       "      <th>LLM_Answer</th>\n",
       "      <th>Exam_Answers</th>\n",
       "      <th>Answered_Correctly</th>\n",
       "      <th>Too_Many_answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Llama2-70b</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[A, D]</td>\n",
       "      <td>[0, 3]</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Llama2-70b</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[A]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Llama2-70b</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[A]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Llama2-70b</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[D]</td>\n",
       "      <td>[2]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Llama2-70b</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[C]</td>\n",
       "      <td>[2]</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>Llama2-70b</td>\n",
       "      <td>199</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[C]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>Llama2-70b</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[D]</td>\n",
       "      <td>[3]</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>Llama2-70b</td>\n",
       "      <td>201</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[A]</td>\n",
       "      <td>[3]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>Llama2-70b</td>\n",
       "      <td>202</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[C]</td>\n",
       "      <td>[2]</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>Llama2-70b</td>\n",
       "      <td>203</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[B]</td>\n",
       "      <td>[3]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>204 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Model QuestionIndex SamplingIndex NumberOfCorrectLLMAnswers  \\\n",
       "0    Llama2-70b             0             0                         2   \n",
       "1    Llama2-70b             1             0                         1   \n",
       "2    Llama2-70b             2             0                         1   \n",
       "3    Llama2-70b             3             0                         0   \n",
       "4    Llama2-70b             4             0                         1   \n",
       "..          ...           ...           ...                       ...   \n",
       "199  Llama2-70b           199             0                         0   \n",
       "200  Llama2-70b           200             0                         1   \n",
       "201  Llama2-70b           201             0                         0   \n",
       "202  Llama2-70b           202             0                         1   \n",
       "203  Llama2-70b           203             0                         0   \n",
       "\n",
       "    NumberOfCorrectExamAnswers  Ratio LLM_Answer Exam_Answers  \\\n",
       "0                            2    1.0     [A, D]       [0, 3]   \n",
       "1                            1    1.0        [A]          [0]   \n",
       "2                            1    1.0        [A]          [0]   \n",
       "3                            1    0.0        [D]          [2]   \n",
       "4                            1    1.0        [C]          [2]   \n",
       "..                         ...    ...        ...          ...   \n",
       "199                          1    0.0        [C]          [0]   \n",
       "200                          1    1.0        [D]          [3]   \n",
       "201                          1    0.0        [A]          [3]   \n",
       "202                          1    1.0        [C]          [2]   \n",
       "203                          1    0.0        [B]          [3]   \n",
       "\n",
       "    Answered_Correctly Too_Many_answers  \n",
       "0                 True            False  \n",
       "1                 True            False  \n",
       "2                 True            False  \n",
       "3                False            False  \n",
       "4                 True            False  \n",
       "..                 ...              ...  \n",
       "199              False            False  \n",
       "200               True            False  \n",
       "201              False            False  \n",
       "202               True            False  \n",
       "203              False            False  \n",
       "\n",
       "[204 rows x 10 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of Questions</th>\n",
       "      <th>Correctly Answered</th>\n",
       "      <th>Incorrectly Answered</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Accuracy Partial</th>\n",
       "      <th>Model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>204</td>\n",
       "      <td>127</td>\n",
       "      <td>77</td>\n",
       "      <td>0.622549</td>\n",
       "      <td>0.682731</td>\n",
       "      <td>Mixtral-8x-7b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>204</td>\n",
       "      <td>76</td>\n",
       "      <td>128</td>\n",
       "      <td>0.372549</td>\n",
       "      <td>0.502008</td>\n",
       "      <td>Phi-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>204</td>\n",
       "      <td>114</td>\n",
       "      <td>90</td>\n",
       "      <td>0.558824</td>\n",
       "      <td>0.626506</td>\n",
       "      <td>Llama2-70b</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Number of Questions Correctly Answered Incorrectly Answered  Accuracy  \\\n",
       "0                 204                127                   77  0.622549   \n",
       "1                 204                 76                  128  0.372549   \n",
       "2                 204                114                   90  0.558824   \n",
       "\n",
       "  Accuracy Partial          Model  \n",
       "0         0.682731  Mixtral-8x-7b  \n",
       "1         0.502008          Phi-2  \n",
       "2         0.626506     Llama2-70b  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 22 key-value pairs and 543 tensors from ../models/yi-34b-200k.Q5_K_M.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.name str              = 01-ai_yi-34b-200k\n",
      "llama_model_loader: - kv   2:                       llama.context_length u32              = 200000\n",
      "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 7168\n",
      "llama_model_loader: - kv   4:                          llama.block_count u32              = 60\n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 20480\n",
      "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 56\n",
      "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 5000000.000000\n",
      "llama_model_loader: - kv  11:                          general.file_type u32              = 17\n",
      "llama_model_loader: - kv  12:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  13:                      tokenizer.ggml.tokens arr[str,64000]   = [\"<unk>\", \"<|startoftext|>\", \"<|endof...\n",
      "llama_model_loader: - kv  14:                      tokenizer.ggml.scores arr[f32,64000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
      "llama_model_loader: - kv  15:                  tokenizer.ggml.token_type arr[i32,64000]   = [2, 3, 3, 3, 3, 3, 1, 1, 1, 3, 3, 3, ...\n",
      "llama_model_loader: - kv  16:                tokenizer.ggml.bos_token_id u32              = 1\n",
      "llama_model_loader: - kv  17:                tokenizer.ggml.eos_token_id u32              = 2\n",
      "llama_model_loader: - kv  18:            tokenizer.ggml.padding_token_id u32              = 0\n",
      "llama_model_loader: - kv  19:               tokenizer.ggml.add_bos_token bool             = false\n",
      "llama_model_loader: - kv  20:               tokenizer.ggml.add_eos_token bool             = false\n",
      "llama_model_loader: - kv  21:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:  121 tensors\n",
      "llama_model_loader: - type q5_K:  361 tensors\n",
      "llama_model_loader: - type q6_K:   61 tensors\n",
      "llm_load_vocab: mismatch in special tokens definition ( 498/64000 vs 267/64000 ).\n",
      "llm_load_print_meta: format           = GGUF V3 (latest)\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = SPM\n",
      "llm_load_print_meta: n_vocab          = 64000\n",
      "llm_load_print_meta: n_merges         = 0\n",
      "llm_load_print_meta: n_ctx_train      = 200000\n",
      "llm_load_print_meta: n_embd           = 7168\n",
      "llm_load_print_meta: n_head           = 56\n",
      "llm_load_print_meta: n_head_kv        = 8\n",
      "llm_load_print_meta: n_layer          = 60\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_embd_head_k    = 128\n",
      "llm_load_print_meta: n_embd_head_v    = 128\n",
      "llm_load_print_meta: n_gqa            = 7\n",
      "llm_load_print_meta: n_embd_k_gqa     = 1024\n",
      "llm_load_print_meta: n_embd_v_gqa     = 1024\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 20480\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 5000000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_yarn_orig_ctx  = 200000\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: model type       = 30B\n",
      "llm_load_print_meta: model ftype      = Q5_K - Medium\n",
      "llm_load_print_meta: model params     = 34.39 B\n",
      "llm_load_print_meta: model size       = 22.65 GiB (5.66 BPW) \n",
      "llm_load_print_meta: general.name     = 01-ai_yi-34b-200k\n",
      "llm_load_print_meta: BOS token        = 1 '<|startoftext|>'\n",
      "llm_load_print_meta: EOS token        = 2 '<|endoftext|>'\n",
      "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
      "llm_load_print_meta: PAD token        = 0 '<unk>'\n",
      "llm_load_print_meta: LF token         = 315 '<0x0A>'\n",
      "llm_load_tensors: ggml ctx size =    0.62 MiB\n",
      "llm_load_tensors: offloading 60 repeating layers to GPU\n",
      "llm_load_tensors: offloading non-repeating layers to GPU\n",
      "llm_load_tensors: offloaded 61/61 layers to GPU\n",
      "llm_load_tensors:        CPU buffer size =   300.78 MiB\n",
      "llm_load_tensors:      CUDA0 buffer size = 11632.80 MiB\n",
      "llm_load_tensors:      CUDA1 buffer size = 11260.10 MiB\n",
      "....................................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 1100\n",
      "llama_new_context_with_model: freq_base  = 10000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "llama_kv_cache_init:      CUDA0 KV buffer size =   133.20 MiB\n",
      "llama_kv_cache_init:      CUDA1 KV buffer size =   124.61 MiB\n",
      "llama_new_context_with_model: KV self size  =  257.81 MiB, K (f16):  128.91 MiB, V (f16):  128.91 MiB\n",
      "llama_new_context_with_model:  CUDA_Host input buffer size   =    32.31 MiB\n",
      "llama_new_context_with_model:      CUDA0 compute buffer size =   361.82 MiB\n",
      "llama_new_context_with_model:      CUDA1 compute buffer size =   361.82 MiB\n",
      "llama_new_context_with_model:  CUDA_Host compute buffer size =    30.80 MiB\n",
      "llama_new_context_with_model: graph splits (measure): 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>QuestionIndex</th>\n",
       "      <th>SamplingIndex</th>\n",
       "      <th>NumberOfCorrectLLMAnswers</th>\n",
       "      <th>NumberOfCorrectExamAnswers</th>\n",
       "      <th>Ratio</th>\n",
       "      <th>LLM_Answer</th>\n",
       "      <th>Exam_Answers</th>\n",
       "      <th>Answered_Correctly</th>\n",
       "      <th>Too_Many_answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Yi-34b</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>[A, C]</td>\n",
       "      <td>[0, 3]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yi-34b</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[A]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yi-34b</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[A]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Yi-34b</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[A]</td>\n",
       "      <td>[2]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Yi-34b</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[C]</td>\n",
       "      <td>[2]</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>Yi-34b</td>\n",
       "      <td>199</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[A]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>Yi-34b</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[D]</td>\n",
       "      <td>[3]</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>Yi-34b</td>\n",
       "      <td>201</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[A]</td>\n",
       "      <td>[3]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>Yi-34b</td>\n",
       "      <td>202</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[C]</td>\n",
       "      <td>[2]</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>Yi-34b</td>\n",
       "      <td>203</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[B]</td>\n",
       "      <td>[3]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>204 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Model QuestionIndex SamplingIndex NumberOfCorrectLLMAnswers  \\\n",
       "0    Yi-34b             0             0                         1   \n",
       "1    Yi-34b             1             0                         1   \n",
       "2    Yi-34b             2             0                         1   \n",
       "3    Yi-34b             3             0                         0   \n",
       "4    Yi-34b             4             0                         1   \n",
       "..      ...           ...           ...                       ...   \n",
       "199  Yi-34b           199             0                         1   \n",
       "200  Yi-34b           200             0                         1   \n",
       "201  Yi-34b           201             0                         0   \n",
       "202  Yi-34b           202             0                         1   \n",
       "203  Yi-34b           203             0                         0   \n",
       "\n",
       "    NumberOfCorrectExamAnswers  Ratio LLM_Answer Exam_Answers  \\\n",
       "0                            2    0.5     [A, C]       [0, 3]   \n",
       "1                            1    1.0        [A]          [0]   \n",
       "2                            1    1.0        [A]          [0]   \n",
       "3                            1    0.0        [A]          [2]   \n",
       "4                            1    1.0        [C]          [2]   \n",
       "..                         ...    ...        ...          ...   \n",
       "199                          1    1.0        [A]          [0]   \n",
       "200                          1    1.0        [D]          [3]   \n",
       "201                          1    0.0        [A]          [3]   \n",
       "202                          1    1.0        [C]          [2]   \n",
       "203                          1    0.0        [B]          [3]   \n",
       "\n",
       "    Answered_Correctly Too_Many_answers  \n",
       "0                False            False  \n",
       "1                 True            False  \n",
       "2                 True            False  \n",
       "3                False            False  \n",
       "4                 True            False  \n",
       "..                 ...              ...  \n",
       "199               True            False  \n",
       "200               True            False  \n",
       "201              False            False  \n",
       "202               True            False  \n",
       "203              False            False  \n",
       "\n",
       "[204 rows x 10 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of Questions</th>\n",
       "      <th>Correctly Answered</th>\n",
       "      <th>Incorrectly Answered</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Accuracy Partial</th>\n",
       "      <th>Model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>204</td>\n",
       "      <td>127</td>\n",
       "      <td>77</td>\n",
       "      <td>0.622549</td>\n",
       "      <td>0.682731</td>\n",
       "      <td>Mixtral-8x-7b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>204</td>\n",
       "      <td>76</td>\n",
       "      <td>128</td>\n",
       "      <td>0.372549</td>\n",
       "      <td>0.502008</td>\n",
       "      <td>Phi-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>204</td>\n",
       "      <td>114</td>\n",
       "      <td>90</td>\n",
       "      <td>0.558824</td>\n",
       "      <td>0.626506</td>\n",
       "      <td>Llama2-70b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>204</td>\n",
       "      <td>105</td>\n",
       "      <td>99</td>\n",
       "      <td>0.514706</td>\n",
       "      <td>0.590361</td>\n",
       "      <td>Yi-34b</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Number of Questions Correctly Answered Incorrectly Answered  Accuracy  \\\n",
       "0                 204                127                   77  0.622549   \n",
       "1                 204                 76                  128  0.372549   \n",
       "2                 204                114                   90  0.558824   \n",
       "3                 204                105                   99  0.514706   \n",
       "\n",
       "  Accuracy Partial          Model  \n",
       "0         0.682731  Mixtral-8x-7b  \n",
       "1         0.502008          Phi-2  \n",
       "2         0.626506     Llama2-70b  \n",
       "3         0.590361         Yi-34b  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 19 key-value pairs and 723 tensors from ../models/llama-65b.Q5_K_M.gguf (version GGUF V2)\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.name str              = meta-llama-65b\n",
      "llama_model_loader: - kv   2:                       llama.context_length u32              = 2048\n",
      "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 8192\n",
      "llama_model_loader: - kv   4:                          llama.block_count u32              = 80\n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 22016\n",
      "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 64\n",
      "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 64\n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  10:                          general.file_type u32              = 17\n",
      "llama_model_loader: - kv  11:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  12:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
      "llama_model_loader: - kv  13:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
      "llama_model_loader: - kv  14:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
      "llama_model_loader: - kv  15:                tokenizer.ggml.bos_token_id u32              = 1\n",
      "llama_model_loader: - kv  16:                tokenizer.ggml.eos_token_id u32              = 2\n",
      "llama_model_loader: - kv  17:            tokenizer.ggml.unknown_token_id u32              = 0\n",
      "llama_model_loader: - kv  18:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:  161 tensors\n",
      "llama_model_loader: - type q5_K:  481 tensors\n",
      "llama_model_loader: - type q6_K:   81 tensors\n",
      "llm_load_vocab: special tokens definition check successful ( 259/32000 ).\n",
      "llm_load_print_meta: format           = GGUF V2\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = SPM\n",
      "llm_load_print_meta: n_vocab          = 32000\n",
      "llm_load_print_meta: n_merges         = 0\n",
      "llm_load_print_meta: n_ctx_train      = 2048\n",
      "llm_load_print_meta: n_embd           = 8192\n",
      "llm_load_print_meta: n_head           = 64\n",
      "llm_load_print_meta: n_head_kv        = 64\n",
      "llm_load_print_meta: n_layer          = 80\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_embd_head_k    = 128\n",
      "llm_load_print_meta: n_embd_head_v    = 128\n",
      "llm_load_print_meta: n_gqa            = 1\n",
      "llm_load_print_meta: n_embd_k_gqa     = 8192\n",
      "llm_load_print_meta: n_embd_v_gqa     = 8192\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 22016\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 10000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_yarn_orig_ctx  = 2048\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: model type       = 65B\n",
      "llm_load_print_meta: model ftype      = Q5_K - Medium\n",
      "llm_load_print_meta: model params     = 65.29 B\n",
      "llm_load_print_meta: model size       = 43.06 GiB (5.67 BPW) \n",
      "llm_load_print_meta: general.name     = meta-llama-65b\n",
      "llm_load_print_meta: BOS token        = 1 '<s>'\n",
      "llm_load_print_meta: EOS token        = 2 '</s>'\n",
      "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
      "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
      "llm_load_tensors: ggml ctx size =    0.83 MiB\n"
     ]
    }
   ],
   "source": [
    "valid_question_answer = False  \n",
    "#Create a dataframe with the size of NUM_OF_SHUFFLES which contains the dataframe llm_exam_result\n",
    "shuffled_evalutation_df = pd.DataFrame(columns=[ 'Number of Questions','Correctly Answered','Incorrectly Answered','Accuracy','Accuracy Partial'])\n",
    "questions  = pd.read_parquet(QUESTIONS_BANK)\n",
    "\n",
    "#Take the first 20 questions\n",
    "#questions = questions.head(20)\n",
    "\n",
    "#questions = extract_answer_from_text_file(\"../data/questionbank_cisco_CCNP.txt\")\n",
    "callback_manager = CallbackManager([StreamingStdOutCallbackHandler()])\n",
    "prompt_template = PromptTemplate.from_template(CCNA_5_SHOT_TEMPLATE_NO_WHITESPACE_AT_FINAL_ANW)\n",
    "\n",
    "#Iterate over each model definied in the MODEL_PATH dictionary\n",
    "for model, model_path in MODEL_PATH.items():\n",
    "     #Load the model wiht LLamaCpp\n",
    "    llm = LlamaCpp(\n",
    "        model_path= model_path,\n",
    "        n_gpu_layers=128,\n",
    "        n_batch=1024,\n",
    "        n_ctx=1100,\n",
    "        temperature=TEMPERATURE,\n",
    "        top_p=1,\n",
    "        max_tokens = 3,\n",
    "        #callback_manager=callback_manager,\n",
    "        verbose=False,  # Verbose is required to pass to the callback manager\n",
    "    )\n",
    "\n",
    "    chain = prompt_template | llm\n",
    "    for shuffled_iteration in range(NUM_OF_SHUFFLES):\n",
    "        llm_exam_result = pd.DataFrame(columns = [\"Model\", \"QuestionIndex\", \"SamplingIndex\", \"NumberOfCorrectLLMAnswers\", \"NumberOfCorrectExamAnswers\", \"Ratio\", \"LLM_Answer\", \"Exam_Answers\", \"Answered_Correctly\",  \"Too_Many_answers\"]) \n",
    "        #Iterate over each question in the question dataframe\n",
    "        for index_question, row in questions.iterrows():\n",
    "            question = row['question']\n",
    "            choices = row['choices']\n",
    "            answers = row['answer']\n",
    "            num_of_correct_answer = len(answers)\n",
    "\n",
    "            choices = format_choices_for_llm(choices)\n",
    "\n",
    "            #Only if shuffle is enabled, shuffle the choices\n",
    "            if shuffled_iteration > 0:\n",
    "                choices, answers = shuffle_choices_and_update_answer(row['choices'], row['answer'])\n",
    "                num_of_correct_answer = len(answers)\n",
    "                choices = format_choices_for_llm(choices)\n",
    "            #Empty the char_probabilities dictionary for each question\n",
    "            char_probabilities = {}\n",
    "\n",
    "            #Iterate over the maximum sampling rate\n",
    "            for index_sampling in range(MAX_SAMPLING_RATE):\n",
    "                # Invoke the chain with the question and choices              \n",
    "                \n",
    "                                \n",
    "                #print(f\"Question: {question}\")\n",
    "                #print(choices)\n",
    "\n",
    "                llm_answer = chain.invoke({\"Exam_Question\" : row['question'], \"Exam_Choices\" : choices})            \n",
    "                # Check if the answer is in the expected format\n",
    "                if extract_answer(llm_answer) is not None:\n",
    "                    # Extract the correct answers from the LLM answer and analyse the answer\n",
    "                    num_of_correct_llm_answer, answerLLm, too_many_answers, answered_correctly = evaluation_sampling(llm_answer, answers, num_of_correct_answer)\n",
    "                    #Save the current sampling index -- How of the question has been asked until the answer was in the correct format\n",
    "                    sample_Index = index_sampling\n",
    "                    valid_question_answer = True\n",
    "                    break\n",
    "            \n",
    "            #Depending on the result of the answer, add the result to the dataframe\n",
    "            if not valid_question_answer:\n",
    "                new_row = pd.DataFrame({\"Model\": [model], \"QuestionIndex\": [index_question], \"SamplingIndex\": [-1], \"NumberOfCorrectLLMAnswers\": [0], \"NumberOfCorrectExamAnswers\": [num_of_correct_answer], \"Ratio\": [-1], \"LLM_Answer\": [llm_answer], \"Exam_Answers\": [answers]})\n",
    "                llm_exam_result = pd.concat([llm_exam_result, new_row], ignore_index=True)\n",
    "            else:\n",
    "                new_row = pd.DataFrame({\"Model\": [model], \"QuestionIndex\": [index_question], \"SamplingIndex\": [sample_Index], \"NumberOfCorrectLLMAnswers\": [num_of_correct_llm_answer], \"NumberOfCorrectExamAnswers\": [num_of_correct_answer], \"Ratio\": [num_of_correct_llm_answer/num_of_correct_answer], \"LLM_Answer\": [answerLLm], \"Exam_Answers\": [answers], \"Answered_Correctly\" : [answered_correctly], \"Too_Many_answers\": [too_many_answers]})\n",
    "                llm_exam_result = pd.concat([llm_exam_result, new_row], ignore_index=True)\n",
    "                valid_question_answer = False\n",
    "        answered_correctly = False\n",
    "        #Concat the the dataframe returned by evaulation to one dataframe\n",
    "        display(llm_exam_result)\n",
    "        #llm_exam_result.to_pickle(f\"../data/{model}_shuffled_{shuffled_iteration}_mmlu.pkl\")\n",
    "        evaluation_df = evaluation(llm_exam_result)\n",
    "        #Concat the evaluation dataframe to the complete dataframe\n",
    "        shuffled_evalutation_df = pd.concat([shuffled_evalutation_df, evaluation_df], ignore_index=True)\n",
    "        display(shuffled_evalutation_df)\n",
    "\n",
    "#plot_evaluation(shuffled_evalutation_df)\n",
    "model_statistics = calculate_model_statistics(shuffled_evalutation_df)\n",
    "display(model_statistics)\n",
    "plot_evaluation(model_statistics)\n",
    "#shuffled_evalutation_df.to_pickle(OUTPUT_EVALUATION_DETAILED)\n",
    "#model_statistics.to_pickle(OUTPUT_EVALUATION)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model, model_path in MODEL_PATH.items():\n",
    "    print(f\"Model: {model}\")\n",
    "    for shuffled_iteration in range(NUM_OF_SHUFFLES):\n",
    "        llm_exam_result = pd.read_pickle(f\"../data/{model}_shuffled_{shuffled_iteration}_201_301.pkl\")\n",
    "        evaluation_df = evaluation(llm_exam_result)\n",
    "        #Concat the evaluation dataframe to the complete dataframe\n",
    "        shuffled_evalutation_df = pd.concat([shuffled_evalutation_df, evaluation_df], ignore_index=True)\n",
    "model_statistics = calculate_model_statistics(shuffled_evalutation_df)\n",
    "display(model_statistics)\n",
    "plot_evaluation(model_statistics)\n",
    "shuffled_evalutation_df.to_pickle(OUTPUT_EVALUATION_DETAILED)\n",
    "model_statistics.to_pickle(OUTPUT_EVALUATION)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
